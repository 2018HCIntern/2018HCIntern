{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (0) into shape (1000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-667cee54a38b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m   \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-667cee54a38b>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m   \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m   \u001b[0mtest_rosenbrock_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-667cee54a38b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim)\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdifferential_evolution_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_cross\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-667cee54a38b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, evaluator, population_size, f, cr, eps, n_cross, max_iter, monitor_cycle, out, show_progress, show_progress_nth_cycle, insert_solution_vector, dither_constant)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_index\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-667cee54a38b>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_random_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# score the population please\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_population\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mconverged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mmonitor_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-667cee54a38b>\u001b[0m in \u001b[0;36mscore_population\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mii\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulation_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mtmp_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mii\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mevolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (0) into shape (1000)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "class differential_evolution_optimizer(object):\n",
    "  \"\"\"\n",
    "This is a python implementation of differential evolution\n",
    "It assumes an evaluator class is passed in that has the following\n",
    "functionality\n",
    "data members:\n",
    " n              :: The number of parameters\n",
    " domain         :: a  list [(low,high)]*n\n",
    "                   with approximate upper and lower limits for each parameter\n",
    " x              :: a place holder for a final solution\n",
    "\n",
    " also a function called 'target' is needed.\n",
    " This function should take a parameter vector as input and return a the function to be minimized.\n",
    "\n",
    " The code below was implemented on the basis of the following sources of information:\n",
    " 1. http://www.icsi.berkeley.edu/~storn/code.html\n",
    " 2. http://www.daimi.au.dk/~krink/fec05/articles/JV_ComparativeStudy_CEC04.pdf\n",
    " 3. http://ocw.mit.edu/NR/rdonlyres/Sloan-School-of-Management/15-099Fall2003/A40397B9-E8FB-4B45-A41B-D1F69218901F/0/ses2_storn_price.pdf\n",
    "\n",
    "\n",
    " The developers of the differential evolution method have this advice:\n",
    " (taken from ref. 1)\n",
    "\n",
    "If you are going to optimize your own objective function with DE, you may try the\n",
    "following classical settings for the input file first: Choose method e.g. DE/rand/1/bin,\n",
    "set the number of parents NP to 10 times the number of parameters, select weighting\n",
    "factor F=0.8, and crossover constant CR=0.9. It has been found recently that selecting\n",
    "F from the interval [0.5, 1.0] randomly for each generation or for each difference\n",
    "vector, a technique called dither, improves convergence behaviour significantly,\n",
    "especially for noisy objective functions. It has also been found that setting CR to a\n",
    "low value, e.g. CR=0.2 helps optimizing separable functions since it fosters the search\n",
    "along the coordinate axes. On the contrary this choice is not effective if parameter\n",
    "dependence is encountered, something which is frequently occuring in real-world optimization\n",
    "problems rather than artificial test functions. So for parameter dependence the choice of\n",
    "CR=0.9 is more appropriate. Another interesting empirical finding is that rasing NP above,\n",
    "say, 40 does not substantially improve the convergence, independent of the number of\n",
    "parameters. It is worthwhile to experiment with these suggestions. Make sure that you\n",
    "initialize your parameter vectors by exploiting their full numerical range, i.e. if a\n",
    "parameter is allowed to exhibit values in the range [-100, 100] it's a good idea to pick\n",
    "the initial values from this range instead of unnecessarily restricting diversity.\n",
    "\n",
    "Keep in mind that different problems often require different settings for NP, F and CR\n",
    "(have a look into the different papers to get a feeling for the settings). If you still\n",
    "get misconvergence you might want to try a different method. We mostly use DE/rand/1/... or DE/best/1/... .\n",
    "The crossover method is not so important although Ken Price claims that binomial is never\n",
    "worse than exponential. In case of misconvergence also check your choice of objective\n",
    "function. There might be a better one to describe your problem. Any knowledge that you\n",
    "have about the problem should be worked into the objective function. A good objective\n",
    "function can make all the difference.\n",
    "\n",
    "Note: NP is called population size in the routine below.)\n",
    "Note: [0.5,1.0] dither is the default behavior unless f is set to a value other then None.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self,\n",
    "               evaluator,\n",
    "               population_size=50,\n",
    "               f=None,\n",
    "               cr=0.9,\n",
    "               eps=1e-2,\n",
    "               n_cross=1,\n",
    "               max_iter=10000,\n",
    "               monitor_cycle=200,\n",
    "               out=None,\n",
    "               show_progress=False,\n",
    "               show_progress_nth_cycle=1,\n",
    "               insert_solution_vector=None,\n",
    "               dither_constant=0.4):\n",
    "    self.dither=dither_constant\n",
    "    self.show_progress=show_progress\n",
    "    self.show_progress_nth_cycle=show_progress_nth_cycle\n",
    "    self.evaluator = evaluator\n",
    "    self.population_size = population_size\n",
    "    self.f = f\n",
    "    self.cr = cr\n",
    "    self.n_cross = n_cross\n",
    "    self.max_iter = max_iter\n",
    "    self.monitor_cycle = monitor_cycle\n",
    "    self.vector_length = evaluator.n\n",
    "    self.eps = eps\n",
    "    self.population = []\n",
    "    self.seeded = False\n",
    "    if insert_solution_vector is not None:\n",
    "      assert len( insert_solution_vector )==self.vector_length\n",
    "      self.seeded = insert_solution_vector\n",
    "    for ii in range(self.population_size):\n",
    "      self.population.append( np.zeros((self.vector_length,0)) )\n",
    "\n",
    "\n",
    "    self.scores = np.zeros((self.population_size,1000))\n",
    "    self.optimize()\n",
    "    self.best_score = np.min( self.scores )\n",
    "    self.best_vector = self.population[ np.min_index( self.scores ) ]\n",
    "    self.evaluator.x = self.best_vector\n",
    "    if self.show_progress:\n",
    "      self.evaluator.print_status(\n",
    "            np.min(self.scores),\n",
    "            np.mean(self.scores),\n",
    "            self.population[ np.min_index( self.scores ) ],\n",
    "            'Final')\n",
    "\n",
    "\n",
    "  def optimize(self):\n",
    "    # initialise the population please\n",
    "    self.make_random_population()\n",
    "    # score the population please\n",
    "    self.score_population()\n",
    "    converged = False\n",
    "    monitor_score = np.min( self.scores )\n",
    "    self.count = 0\n",
    "    while not converged:\n",
    "      self.evolve()\n",
    "      location = np.min_index( self.scores )\n",
    "      if self.show_progress:\n",
    "        if self.count%self.show_progress_nth_cycle==0:\n",
    "          # make here a call to a custom print_status function in the evaluator function\n",
    "          # the function signature should be (min_target, mean_target, best vector)\n",
    "          self.evaluator.print_status(\n",
    "            np.min(self.scores),\n",
    "            np.mean(self.scores),\n",
    "            self.population[ np.min_index( self.scores ) ],\n",
    "            self.count)\n",
    "\n",
    "      self.count += 1\n",
    "      if self.count%self.monitor_cycle==0:\n",
    "        if (monitor_score-np.min(self.scores) ) < self.eps:\n",
    "          converged = True\n",
    "        else:\n",
    "         monitor_score = np.min(self.scores)\n",
    "      rd = (np.mean(self.scores) - np.min(self.scores) )\n",
    "      rd = rd*rd/(np.min(self.scores)*np.min(self.scores) + self.eps )\n",
    "      if ( rd < self.eps ):\n",
    "        converged = True\n",
    "\n",
    "\n",
    "      if self.count>=self.max_iter:\n",
    "        converged =True\n",
    "\n",
    "  def make_random_population(self):\n",
    "    for ii in range(self.vector_length):\n",
    "      delta  = self.evaluator.domain[ii][1]-self.evaluator.domain[ii][0]\n",
    "      offset = self.evaluator.domain[ii][0]\n",
    "      random_values = np.random.uniform(size = self.population_size)\n",
    "      random_values = random_values*delta+offset\n",
    "      # now please place these values ni the proper places in the\n",
    "      # vectors of the population we generated\n",
    "      for vector, item in zip(self.population,random_values):\n",
    "        vector[ii] = item\n",
    "    if self.seeded is not False:\n",
    "      self.population[0] = self.seeded\n",
    "\n",
    "  def score_population(self):\n",
    "    for vector,ii in zip(self.population,range(self.population_size)):\n",
    "      tmp_score = self.evaluator.target(vector)\n",
    "      self.scores[ii]=tmp_score\n",
    "\n",
    "  def evolve(self):\n",
    "    for ii in range(self.population_size):\n",
    "      rnd = np.random.uniform(size = self.population_size-1)\n",
    "      permut = np.sort_permutation(rnd)\n",
    "      # make parent indices\n",
    "      i1=permut[0]\n",
    "      if (i1>=ii):\n",
    "        i1+=1\n",
    "      i2=permut[1]\n",
    "      if (i2>=ii):\n",
    "        i2+=1\n",
    "      i3=permut[2]\n",
    "      if (i3>=ii):\n",
    "        i3+=1\n",
    "      #\n",
    "      x1 = self.population[ i1 ]\n",
    "      x2 = self.population[ i2 ]\n",
    "      x3 = self.population[ i3 ]\n",
    "\n",
    "      if self.f is None:\n",
    "        use_f = random.random()/2.0 + 0.5\n",
    "      else:\n",
    "        use_f = self.f\n",
    "\n",
    "      vi = x1 + use_f*(x2-x3)\n",
    "      # prepare the offspring vector please\n",
    "      rnd = np.random.uniform(size = self.vector_length)\n",
    "      permut = np.sort_permutation(rnd)\n",
    "      test_vector = self.population[ii].copy()\n",
    "      # first the parameters that sure cross over\n",
    "      for jj in range( self.vector_length  ):\n",
    "        if (jj<self.n_cross):\n",
    "          test_vector[ permut[jj] ] = vi[ permut[jj] ]\n",
    "        else:\n",
    "          if (rnd[jj]>self.cr):\n",
    "            test_vector[ permut[jj] ] = vi[ permut[jj] ]\n",
    "      # get the score please\n",
    "      test_score = self.evaluator.target( test_vector )\n",
    "      # check if the score if lower\n",
    "      if test_score < self.scores[ii] :\n",
    "        self.scores[ii] = test_score\n",
    "        self.population[ii] = test_vector\n",
    "\n",
    "\n",
    "  def show_population(self):\n",
    "    print (\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    for vec in self.population:\n",
    "      print(list(vec))\n",
    "    print (\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "\n",
    "\n",
    "class test_function(object):\n",
    "  def __init__(self):\n",
    "    self.x = None\n",
    "    self.n = 9\n",
    "    self.domain = [ (-100,100) ]*self.n\n",
    "    self.optimizer =  differential_evolution_optimizer(self,population_size=100,n_cross=5)\n",
    "    assert np.sum(self.x*self.x)<1e-5\n",
    "\n",
    "  def target(self, vector):\n",
    "    tmp = vector.copy()\n",
    "    result = (np.sum(np.cos(tmp*10))+self.n+1)*np.sum( (tmp)*(tmp) )\n",
    "    return result\n",
    "\n",
    "\n",
    "class test_rosenbrock_function(object):\n",
    "  def __init__(self, dim=5):\n",
    "    self.x = None\n",
    "    self.n = 2*dim\n",
    "    self.dim = dim\n",
    "    self.domain = [ (1,3) ]*self.n\n",
    "    self.optimizer =  differential_evolution_optimizer(self,population_size=min(self.n*10,40),n_cross=self.n,cr=0.9, eps=1e-8, show_progress=True)\n",
    "    print (list(self.x))\n",
    "    for x in self.x:\n",
    "      assert abs(x-1.0)<1e-2\n",
    "\n",
    "\n",
    "  def target(self, vector):\n",
    "    tmp = vector.copy()\n",
    "    x_vec = vector[0:self.dim]\n",
    "    y_vec = vector[self.dim:]\n",
    "    result=0\n",
    "    for x,y in zip(x_vec,y_vec):\n",
    "      result+=100.0*((y-x*x)**2.0) + (1-x)**2.0\n",
    "    #print list(x_vec), list(y_vec), result\n",
    "    return result\n",
    "\n",
    "  def print_status(self, mins,means,vector,txt):\n",
    "    print (txt,mins, means, list(vector))\n",
    "\n",
    "\n",
    "def run():\n",
    "  random.seed(0)\n",
    "  np.random.seed(0)\n",
    "  test_rosenbrock_function(1)\n",
    "  print( \"OK\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
