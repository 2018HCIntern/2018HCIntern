{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A..papers</th>\n",
       "      <th>A.papers</th>\n",
       "      <th>B.papers</th>\n",
       "      <th>C.papers</th>\n",
       "      <th>Dif.countries</th>\n",
       "      <th>Perc_non_australian</th>\n",
       "      <th>Number.people</th>\n",
       "      <th>PHD</th>\n",
       "      <th>Max.years.univ</th>\n",
       "      <th>Grants.succ</th>\n",
       "      <th>...</th>\n",
       "      <th>SEO.11</th>\n",
       "      <th>SEO.12</th>\n",
       "      <th>SEO.13</th>\n",
       "      <th>SEO.14</th>\n",
       "      <th>SEO.15</th>\n",
       "      <th>SEO.16</th>\n",
       "      <th>SEO.17</th>\n",
       "      <th>SEO.18</th>\n",
       "      <th>SEO.19</th>\n",
       "      <th>Grant.Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A..papers  A.papers  B.papers  C.papers  Dif.countries  \\\n",
       "0        4.0       2.0       0.0       0.0              1   \n",
       "1        6.0      12.0       2.0       2.0              1   \n",
       "2        7.0      20.0      20.0       7.0              2   \n",
       "3        0.0       3.0      13.0       3.0              1   \n",
       "4        3.0       0.0       1.0       0.0              1   \n",
       "\n",
       "   Perc_non_australian  Number.people  PHD  Max.years.univ  Grants.succ  \\\n",
       "0                 0.00              1  0.0             0.0          0.0   \n",
       "1                 1.00              1  1.0            20.0          0.0   \n",
       "2                 0.75              4  2.0            50.0          0.0   \n",
       "3                 1.00              2  2.0            15.0          0.0   \n",
       "4                 0.00              1  1.0            10.0          0.0   \n",
       "\n",
       "       ...       SEO.11  SEO.12  SEO.13  SEO.14  SEO.15  SEO.16  SEO.17  \\\n",
       "0      ...            0       0       0       0       0       0       0   \n",
       "1      ...            0       0       0       0       0       0       0   \n",
       "2      ...            0       0       2       0       0       0       0   \n",
       "3      ...            0       0       2       0       0       0       0   \n",
       "4      ...            0       0       0       0       0       0       1   \n",
       "\n",
       "   SEO.18  SEO.19  Grant.Status  \n",
       "0       0       0             1  \n",
       "1       0       0             1  \n",
       "2       0       0             1  \n",
       "3       0       0             1  \n",
       "4       0       0             0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "file_name = \"../data/train_preprocessed2.csv\"\n",
    "train_df = pd.read_csv(file_name, low_memory = False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data : Divide Test and Train set\n",
    "\n",
    "array = train_df.values\n",
    "\n",
    "data = array[:, 0:70]\n",
    "target = array[:, 70]\n",
    "\n",
    "data, target\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size = test_size, random_state = seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 84.78% (2.85%)\n"
     ]
    }
   ],
   "source": [
    "# XGB (parameter default) Result \n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric = 'auc')\n",
    "\n",
    "# make predictions with kfold cross validation score\n",
    "kfold = KFold(n_splits = 5, random_state = 7)\n",
    "results = cross_val_score(model, data, target, cv = kfold)\n",
    "accuracy = results.mean()*100\n",
    "print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB model Function\n",
    "\n",
    "def XGB_Train_Model_using_KFold(min_child_weight, max_depth, gamma, subsample,  colsample_bytree) : \n",
    "    xgb_params = {\n",
    "        'n_trees' : 20,\n",
    "        'eta' : 0.2,\n",
    "        'max_depth' : int(max_depth),\n",
    "        'subsample' : max(min(subsample, 1), 0),\n",
    "        'objective' : 'reg:linear', \n",
    "        'eval_metric' : 'auc',\n",
    "        'silent' : 1,\n",
    "        'min_child_weight' : int(min_child_weight),\n",
    "        'gamma' : max(gamma, 0), \n",
    "        'colsample_bytree' : max(min(colsample_bytree, 1), 0)\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    kfold = KFold(n_splits = 5, random_state = 7)\n",
    "    results = cross_val_score(model, data, target, cv = kfold)\n",
    "    auc = results.mean()*100\n",
    "    print(\"AUC : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "AUC : 82.14% (5.83%)\n",
      "    1 | 00m05s | \u001b[35m  82.14403\u001b[0m | \u001b[32m            0.6237\u001b[0m | \u001b[32m   7.4242\u001b[0m | \u001b[32m     5.0288\u001b[0m | \u001b[32m           12.6237\u001b[0m | \u001b[32m     0.6509\u001b[0m | \n",
      "AUC : 81.37% (5.61%)\n",
      "    2 | 00m03s |   81.37448 |             0.9829 |    8.4029 |      3.0777 |            18.6693 |      0.8736 | \n",
      "AUC : 82.71% (5.84%)\n",
      "    3 | 00m06s | \u001b[35m  82.70673\u001b[0m | \u001b[32m            0.7951\u001b[0m | \u001b[32m   6.1211\u001b[0m | \u001b[32m     6.5510\u001b[0m | \u001b[32m           12.9404\u001b[0m | \u001b[32m     0.8849\u001b[0m | \n",
      "AUC : 84.62% (3.79%)\n",
      "    4 | 00m09s | \u001b[35m  84.62414\u001b[0m | \u001b[32m            0.8043\u001b[0m | \u001b[32m   2.0873\u001b[0m | \u001b[32m     7.9165\u001b[0m | \u001b[32m            3.1102\u001b[0m | \u001b[32m     0.5233\u001b[0m | \n",
      "AUC : 82.67% (5.38%)\n",
      "    5 | 00m02s |   82.67216 |             0.2636 |    5.9450 |      4.3147 |            10.8440 |      0.6794 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "AUC : 83.33% (2.57%)\n",
      "    6 | 00m25s |   83.32604 |             1.0000 |    0.0000 |      9.5685 |             3.3202 |      0.5000 | \n",
      "AUC : 84.72% (3.15%)\n",
      "    7 | 00m11s | \u001b[35m  84.71592\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   2.7376\u001b[0m | \u001b[32m     6.7550\u001b[0m | \u001b[32m            4.5549\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "AUC : 83.65% (4.14%)\n",
      "    8 | 00m20s |   83.64812 |             1.0000 |    3.1151 |      7.3363 |             4.2098 |      0.5000 | \n",
      "AUC : 82.75% (0.75%)\n",
      "    9 | 00m05s |   82.75162 |             0.1000 |    0.1447 |      5.9655 |             3.3065 |      1.0000 | \n",
      "AUC : 84.34% (3.22%)\n",
      "   10 | 00m12s |   84.33700 |             0.8951 |    1.4146 |      7.9336 |             4.2209 |      1.0000 | \n",
      "AUC : 84.61% (3.23%)\n",
      "   11 | 00m13s |   84.61258 |             1.0000 |    1.4121 |      7.8235 |             1.7359 |      1.0000 | \n",
      "AUC : 82.08% (6.14%)\n",
      "   12 | 00m10s |   82.07515 |             1.0000 |    5.8465 |      4.1450 |            15.1075 |      1.0000 | \n",
      "AUC : 84.87% (3.18%)\n",
      "   13 | 00m13s | \u001b[35m  84.86522\u001b[0m | \u001b[32m            0.5249\u001b[0m | \u001b[32m   1.8041\u001b[0m | \u001b[32m     7.2027\u001b[0m | \u001b[32m            3.0878\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "AUC : 84.56% (3.20%)\n",
      "   14 | 00m16s |   84.55524 |             1.0000 |    2.0359 |      6.1880 |             4.1221 |      1.0000 | \n",
      "AUC : 84.10% (5.31%)\n",
      "   15 | 00m10s |   84.09609 |             0.5142 |    3.2152 |      5.7565 |             6.6598 |      1.0000 | \n",
      "AUC : 83.18% (5.13%)\n",
      "   16 | 00m17s |   83.17746 |             0.7698 |    1.3355 |      8.2264 |             2.5872 |      1.0000 | \n",
      "AUC : 84.82% (3.10%)\n",
      "   17 | 00m16s |   84.81915 |             1.0000 |    1.0845 |      6.8603 |             1.5741 |      0.5000 | \n",
      "AUC : 85.15% (2.62%)\n",
      "   18 | 00m12s | \u001b[35m  85.15212\u001b[0m | \u001b[32m            0.5169\u001b[0m | \u001b[32m   1.4507\u001b[0m | \u001b[32m     7.0916\u001b[0m | \u001b[32m            5.3191\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "AUC : 84.12% (2.96%)\n",
      "   19 | 00m18s |   84.11875 |             1.0000 |    1.9690 |      7.2172 |             2.0054 |      0.5000 | \n",
      "AUC : 84.88% (3.24%)\n",
      "   20 | 00m15s |   84.87663 |             0.7618 |    1.6017 |      7.1663 |             4.0331 |      0.5000 | \n",
      "AUC : 85.62% (2.67%)\n",
      "   21 | 00m07s | \u001b[35m  85.62309\u001b[0m | \u001b[32m            0.2407\u001b[0m | \u001b[32m   2.2791\u001b[0m | \u001b[32m     6.9449\u001b[0m | \u001b[32m            5.6111\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "AUC : 85.31% (2.97%)\n",
      "   22 | 00m09s |   85.31294 |             0.5162 |    2.2062 |      6.9926 |             5.8194 |      0.9764 | \n",
      "AUC : 83.66% (0.85%)\n",
      "   23 | 00m07s |   83.65888 |             0.1000 |    2.2362 |      6.6960 |             4.9218 |      1.0000 | \n",
      "AUC : 83.76% (2.56%)\n",
      "   24 | 00m07s |   83.76269 |             0.1000 |    2.8403 |      7.2179 |             6.4566 |      0.6434 | \n",
      "AUC : 84.90% (3.00%)\n",
      "   25 | 00m11s |   84.89961 |             1.0000 |    0.7684 |      6.7894 |             2.4500 |      1.0000 | \n",
      "AUC : 83.74% (4.95%)\n",
      "   26 | 00m09s |   83.74011 |             0.5401 |    5.9037 |      5.2151 |            12.4738 |      0.9586 | \n",
      "AUC : 82.11% (6.14%)\n",
      "   27 | 00m11s |   82.10958 |             0.9270 |    7.6036 |      4.0304 |            16.6657 |      0.8285 | \n",
      "AUC : 84.07% (2.61%)\n",
      "   28 | 00m08s |   84.07273 |             0.1000 |    1.9604 |      7.2042 |             5.7519 |      0.9495 | \n",
      "AUC : 85.08% (3.02%)\n",
      "   29 | 00m10s |   85.08334 |             0.4347 |    2.7521 |      6.6687 |             5.7381 |      0.7433 | \n",
      "AUC : 85.52% (3.38%)\n",
      "   30 | 00m10s |   85.51978 |             0.4449 |    2.6034 |      7.0080 |             5.5553 |      1.0000 | \n",
      "AUC : 84.97% (3.37%)\n",
      "   31 | 00m08s |   84.96864 |             0.2528 |    2.4192 |      6.5403 |             5.9352 |      1.0000 | \n",
      "AUC : 84.88% (3.50%)\n",
      "   32 | 00m14s |   84.87684 |             0.7733 |    1.9822 |      6.9793 |             5.1315 |      0.7972 | \n",
      "AUC : 83.57% (2.44%)\n",
      "   33 | 00m20s |   83.56710 |             0.9392 |    0.2659 |      8.0354 |             3.7816 |      0.5000 | \n",
      "AUC : 84.95% (3.32%)\n",
      "   34 | 00m14s |   84.94562 |             1.0000 |    2.2012 |      7.0596 |             3.3465 |      1.0000 | \n",
      "AUC : 85.31% (3.27%)\n",
      "   35 | 00m13s |   85.31303 |             0.7277 |    1.1298 |      7.0753 |             1.9995 |      0.7672 | \n",
      "AUC : 81.75% (5.68%)\n",
      "   36 | 00m13s |   81.75352 |             0.9387 |    6.5217 |      5.2364 |            13.6980 |      0.6869 | \n",
      "AUC : 82.99% (5.97%)\n",
      "   37 | 00m11s |   82.99388 |             0.5501 |    6.0473 |      5.7067 |            10.9848 |      0.7765 | \n",
      "AUC : 85.59% (3.37%)\n",
      "   38 | 00m10s |   85.58866 |             0.3621 |    2.3361 |      6.9259 |             5.6202 |      0.8694 | \n",
      "AUC : 85.42% (3.01%)\n",
      "   39 | 00m11s |   85.41637 |             0.4146 |    3.6688 |      6.3947 |             6.7699 |      0.9721 | \n",
      "AUC : 85.85% (2.88%)\n",
      "   40 | 00m11s | \u001b[35m  85.85274\u001b[0m | \u001b[32m            0.3706\u001b[0m | \u001b[32m   2.3711\u001b[0m | \u001b[32m     6.8868\u001b[0m | \u001b[32m            5.6315\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "AUC : 85.21% (3.56%)\n",
      "   41 | 00m13s |   85.20973 |             0.4462 |    2.3118 |      6.8042 |             5.5662 |      1.0000 | \n",
      "AUC : 85.07% (2.94%)\n",
      "   42 | 00m10s |   85.07188 |             0.2263 |    2.8860 |      6.7542 |             6.2304 |      1.0000 | \n",
      "AUC : 84.89% (3.40%)\n",
      "   43 | 00m11s |   84.88824 |             0.4592 |    3.8155 |      6.0276 |             7.1879 |      0.7427 | \n",
      "AUC : 84.50% (3.23%)\n",
      "   44 | 00m17s |   84.49769 |             0.8074 |    1.4005 |      7.5464 |             4.9955 |      0.5000 | \n",
      "AUC : 82.72% (5.12%)\n",
      "   45 | 00m11s |   82.71805 |             0.5381 |    6.5230 |      5.4427 |            12.0991 |      0.7478 | \n",
      "AUC : 84.41% (4.05%)\n",
      "   46 | 00m11s |   84.40602 |             0.2918 |    2.5132 |      6.9359 |             5.8493 |      1.0000 | \n",
      "AUC : 84.44% (3.44%)\n",
      "   47 | 00m09s |   84.44035 |             0.1850 |    3.1277 |      6.4178 |             6.8593 |      0.5000 | \n",
      "AUC : 85.34% (3.10%)\n",
      "   48 | 00m12s |   85.33598 |             0.5375 |    0.9292 |      6.4050 |             3.4778 |      0.9212 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-eaacb866ab2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mxgb_bayesOPT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesianOptimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGB_Train_Model_using_KFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mxgb_bayesOPT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bayes_opt/bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[0;34m(self, init_points, n_iter, acq, kappa, xi, **gp_params)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# Append most recently generated values to X and Y arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/bayes_opt/target_space.py\u001b[0m in \u001b[0;36mobserve_point\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;31m# measure the target function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_observation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-844cb1755036>\u001b[0m in \u001b[0;36mXGB_Train_Model_using_KFold\u001b[0;34m(min_child_weight, max_depth, gamma, subsample, colsample_bytree)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m#n_splits = int(max(n_splits_param, 2))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC : %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             return_times=True)\n\u001b[0;32m--> 206\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#XGB (parameters tuned by Bayesian Optimization) result\n",
    "\n",
    "xgb_params = {\n",
    "    \n",
    "    #Learning Rate \n",
    "    #'eta' : (0.01, 0.2),\n",
    "    \n",
    "    #Minimum sum of weights : to control overfitting\n",
    "    'min_child_weight' : (1, 20), \n",
    "    \n",
    "    #Maximum depth of a tree : to control overfitting\n",
    "    'max_depth' : (2, 10),\n",
    "    \n",
    "    #minimum loss reduction required to make a split : makes algorithm conservative\n",
    "    'gamma' : (0, 10), \n",
    "    \n",
    "    #max_delta_step is not needed since data is not imbalanced\n",
    "    #'max_delta_step' : (0, 10),\n",
    "    \n",
    "    #Fraction of observations to be randomly samples for each tree\n",
    "    #Lower: prevent overfitting\n",
    "    'subsample' : (0.5, 1),\n",
    "    \n",
    "    #Fraction of columns to be randomly samples for each tree\n",
    "    'colsample_bytree' : (0.1, 1),\n",
    "    \n",
    "    #colsamble_bylevel is not needed since subsample and colsample_bytree will do the job\n",
    "    #'colsample_bylevel' = (0.1, 1),\n",
    "    \n",
    "    #L2 regularization term on weights\n",
    "    #'lambda' = (?, ?)\n",
    "    \n",
    "    #L1 regularization term on weight\n",
    "    #'alpha' = (?, ?)\n",
    "    \n",
    "    #scale_pos_weight is not needed since data is not imbalanced\n",
    "    #'scale_pos_weight' = (0, 10)\n",
    "    #'n_splits_param' : (5, 10)\n",
    "}\n",
    "\n",
    "\n",
    "xgb_bayesOPT = BayesianOptimization(XGB_Train_Model_using_KFold, xgb_params)\n",
    "xgb_bayesOPT.maximize(init_points = 5, n_iter = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's auc: 0.94954 + 0.0060144\tcv_agg's l2: 0.0937773 + 0.00539591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9495402224421168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lightGBM (parameter default) result\n",
    "\n",
    "lgb_train = lgb.Dataset(data_train, target_train)\n",
    "lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "cv_results = lgb.cv(lgb_params, lgb_train, num_boost_round=20, nfold=5, \n",
    "                verbose_eval=20, early_stopping_rounds=5)\n",
    "cv_results['auc-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGB model function (eval metric = auc, using kfold)\n",
    "\n",
    "def LGB_Train_Model(learning_rate, max_depth, min_child_weight, colsample_bytree, subsample ) :\n",
    "    lgb_train = lgb.Dataset(data_train, target_train)\n",
    "    lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "    \n",
    "    # specify your configurations as a dict\n",
    "    lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "        \n",
    "        \n",
    "    \n",
    "    'learning_rate': max(learning_rate, 0),\n",
    "    'max_depth': int(max_depth),\n",
    "    'min_child_weight' : int(min_child_weight),\n",
    "    'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "    'subsample' : max(min(subsample, 1), 0)\n",
    "    }\n",
    "\n",
    "    cv_results = lgb.cv(lgb_params, lgb_train, num_boost_round=20, nfold=5, \n",
    "                    verbose_eval=20, early_stopping_rounds=5)\n",
    "\n",
    "    return cv_results['auc-mean'][-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "[20]\tcv_agg's auc: 0.934641 + 0.00900282\tcv_agg's l2: 0.110407 + 0.00650444\n",
      "    1 | 00m00s | \u001b[35m   0.93464\u001b[0m | \u001b[32m            2.1226\u001b[0m | \u001b[32m         0.7158\u001b[0m | \u001b[32m     2.7484\u001b[0m | \u001b[32m            7.0980\u001b[0m | \u001b[32m     0.7328\u001b[0m | \n",
      "    2 | 00m00s | \u001b[35m   0.94739\u001b[0m | \u001b[32m            2.5823\u001b[0m | \u001b[32m         0.5638\u001b[0m | \u001b[32m     8.7595\u001b[0m | \u001b[32m            9.5459\u001b[0m | \u001b[32m     0.8920\u001b[0m | \n",
      "[20]\tcv_agg's auc: 0.943509 + 0.00615786\tcv_agg's l2: 0.098954 + 0.00503382\n",
      "    3 | 00m00s |    0.94351 |             8.7015 |          0.3612 |      3.6977 |             4.5547 |      0.5885 | \n",
      "    4 | 00m00s |    0.92216 |             4.9546 |          1.7841 |      8.4787 |             8.2556 |      0.8559 | \n",
      "[20]\tcv_agg's auc: 0.948378 + 0.00543927\tcv_agg's l2: 0.0933521 + 0.00434557\n",
      "    5 | 00m00s | \u001b[35m   0.94838\u001b[0m | \u001b[32m            1.9040\u001b[0m | \u001b[32m         0.2965\u001b[0m | \u001b[32m     4.4612\u001b[0m | \u001b[32m            8.8118\u001b[0m | \u001b[32m     0.8473\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "[20]\tcv_agg's auc: 0.915504 + 0.00542391\tcv_agg's l2: 0.13673 + 0.00324148\n",
      "    6 | 00m07s |    0.91550 |             9.6609 |          0.0837 |      2.5233 |             9.7798 |      0.5315 | \n",
      "    7 | 00m08s |    0.94126 |             0.1000 |          0.0100 |     10.0000 |             1.0000 |      1.0000 | \n",
      "[20]\tcv_agg's auc: 0.952766 + 0.00594151\tcv_agg's l2: 0.0862288 + 0.0058573\n",
      "    8 | 00m08s | \u001b[35m   0.95277\u001b[0m | \u001b[32m           10.0000\u001b[0m | \u001b[32m         0.2382\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m            1.1592\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "[20]\tcv_agg's auc: 0.908927 + 0.00444548\tcv_agg's l2: 0.151939 + 0.00293792\n",
      "    9 | 00m09s |    0.90893 |             7.8337 |          0.0577 |      2.7372 |             1.1195 |      0.9762 | \n",
      "   10 | 00m08s |    0.94112 |             8.7065 |          0.0100 |      9.9300 |             8.1194 |      0.5000 | \n",
      "   11 | 00m08s |    0.94126 |             0.5060 |          0.0100 |     10.0000 |             5.2679 |      0.5000 | \n",
      "   12 | 00m08s |    0.94126 |             6.2883 |          0.0100 |     10.0000 |             3.0354 |      1.0000 | \n",
      "[20]\tcv_agg's auc: 0.918288 + 0.0218237\tcv_agg's l2: 0.124021 + 0.0179387\n",
      "   13 | 00m09s |    0.91829 |             0.1959 |          1.4116 |      2.0388 |             9.9868 |      0.7545 | \n",
      "   14 | 00m08s |    0.94244 |             9.9828 |          0.0285 |      7.6396 |             5.1289 |      0.9187 | \n",
      "   15 | 00m08s |    0.92904 |             0.1000 |          0.0100 |      4.5184 |             1.0000 |      0.5000 | \n",
      "   16 | 00m08s |    0.94103 |             0.2896 |          0.0150 |      9.5989 |             9.9031 |      0.5278 | \n",
      "   17 | 00m08s |    0.94200 |             5.2656 |          0.0100 |      7.1571 |             9.6858 |      0.5000 | \n",
      "   18 | 00m09s |    0.92264 |             0.1936 |          1.9966 |      9.4055 |             1.0451 |      0.9534 | \n",
      "   19 | 00m09s |    0.88962 |             9.9950 |          1.9135 |      2.6329 |             3.2912 |      0.5033 | \n",
      "[20]\tcv_agg's auc: 0.94953 + 0.00569872\tcv_agg's l2: 0.0925148 + 0.00511249\n",
      "   20 | 00m09s |    0.94953 |             0.1457 |          0.1205 |      6.3444 |             7.3481 |      0.9920 | \n",
      "   21 | 00m09s |    0.94221 |             4.4439 |          0.0100 |      6.9938 |             2.5320 |      0.5000 | \n",
      "   22 | 00m12s |    0.88400 |             5.5154 |          0.0100 |      2.0000 |             7.9275 |      1.0000 | \n",
      "   23 | 00m09s |    0.92169 |             1.0111 |          2.0000 |      7.1111 |            10.0000 |      0.5000 | \n",
      "   24 | 00m08s |    0.88548 |             0.1336 |          0.0460 |      2.6975 |             7.8224 |      0.5126 | \n",
      "   25 | 00m10s |    0.71405 |             0.1000 |          2.0000 |      2.0000 |             1.0000 |      1.0000 | \n",
      "   26 | 00m12s |    0.92264 |            10.0000 |          2.0000 |     10.0000 |            10.0000 |      1.0000 | \n",
      "   27 | 00m14s |    0.93750 |            10.0000 |          0.0100 |      5.5872 |             1.0000 |      0.5000 | \n",
      "   28 | 00m13s |    0.90542 |            10.0000 |          2.0000 |      4.4422 |            10.0000 |      1.0000 | \n",
      "   29 | 00m11s |    0.92264 |            10.0000 |          2.0000 |     10.0000 |             1.0000 |      1.0000 | \n",
      "   30 | 00m12s |    0.94126 |            10.0000 |          0.0100 |     10.0000 |            10.0000 |      1.0000 | \n"
     ]
    }
   ],
   "source": [
    "#lightGBM (parameters tuned with Bayesian Optimization) Result\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate' : (0.01, 2), \n",
    "    'max_depth' : (2, 10), \n",
    "    'min_child_weight' : (1, 10), \n",
    "    'colsample_bytree' : (0.1, 10), \n",
    "    'subsample' : (0.5, 1)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "lgb_bayesOPT = BayesianOptimization(LGB_Train_Model, lgb_params)\n",
    "lgb_bayesOPT.maximize(init_points = 5, n_iter = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:  9.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566.7061882019043 seconds elpased.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(eval_metric = 'auc', n_trees = 20)\n",
    "\n",
    "xgb_params = {\n",
    "    'learning_rate' : [0.2],\n",
    "    'min_child_weight' : np.arange(1, 20, 4),      # 5\n",
    "    'max_depth' : np.arange(2, 10, 2),             # 4 \n",
    "    'gamma' : np.arange(0, 10, 2),                 # 5\n",
    "    #'subsample' : np.arange(0.5, 1.0, 0.1),        # 5\n",
    "    #'colsample_bytree' : np.arange(0.1, 1.0, 0.2), # 5\n",
    "    'objective' : ['reg:linear'],\n",
    "    'silent' : [1],\n",
    "}\n",
    "\n",
    "GSCV = GridSearchCV(xgb_clf, xgb_params, cv = 5, scoring = 'accuracy', n_jobs = 1, verbose = 1)\n",
    "\n",
    "start_time = time.time()\n",
    "GSCV.fit(data, target)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"%s seconds elpased.\"%elapsed_time)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.8352090032154341\n",
      "best parameters: {'gamma': 6, 'learning_rate': 0.2, 'max_depth': 6, 'min_child_weight': 17, 'objective': 'reg:linear', 'silent': 1}\n"
     ]
    }
   ],
   "source": [
    "best_parameters, score, _ = max(GSCV.grid_scores_, key=lambda x: x[1])\n",
    "print('AUC score:', score)\n",
    "print('best parameters:', best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
