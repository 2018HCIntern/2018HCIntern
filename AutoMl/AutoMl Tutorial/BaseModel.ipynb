{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A..papers</th>\n",
       "      <th>A.papers</th>\n",
       "      <th>B.papers</th>\n",
       "      <th>C.papers</th>\n",
       "      <th>Dif.countries</th>\n",
       "      <th>Perc_non_australian</th>\n",
       "      <th>Number.people</th>\n",
       "      <th>PHD</th>\n",
       "      <th>Max.years.univ</th>\n",
       "      <th>Grants.succ</th>\n",
       "      <th>...</th>\n",
       "      <th>SEO.11</th>\n",
       "      <th>SEO.12</th>\n",
       "      <th>SEO.13</th>\n",
       "      <th>SEO.14</th>\n",
       "      <th>SEO.15</th>\n",
       "      <th>SEO.16</th>\n",
       "      <th>SEO.17</th>\n",
       "      <th>SEO.18</th>\n",
       "      <th>SEO.19</th>\n",
       "      <th>Grant.Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A..papers  A.papers  B.papers  C.papers  Dif.countries  \\\n",
       "0        4.0       2.0       0.0       0.0              1   \n",
       "1        6.0      12.0       2.0       2.0              1   \n",
       "2        7.0      20.0      20.0       7.0              2   \n",
       "3        0.0       3.0      13.0       3.0              1   \n",
       "4        3.0       0.0       1.0       0.0              1   \n",
       "\n",
       "   Perc_non_australian  Number.people  PHD  Max.years.univ  Grants.succ  \\\n",
       "0                 0.00              1  0.0             0.0          0.0   \n",
       "1                 1.00              1  1.0            20.0          0.0   \n",
       "2                 0.75              4  2.0            50.0          0.0   \n",
       "3                 1.00              2  2.0            15.0          0.0   \n",
       "4                 0.00              1  1.0            10.0          0.0   \n",
       "\n",
       "       ...       SEO.11  SEO.12  SEO.13  SEO.14  SEO.15  SEO.16  SEO.17  \\\n",
       "0      ...            0       0       0       0       0       0       0   \n",
       "1      ...            0       0       0       0       0       0       0   \n",
       "2      ...            0       0       2       0       0       0       0   \n",
       "3      ...            0       0       2       0       0       0       0   \n",
       "4      ...            0       0       0       0       0       0       1   \n",
       "\n",
       "   SEO.18  SEO.19  Grant.Status  \n",
       "0       0       0             1  \n",
       "1       0       0             1  \n",
       "2       0       0             1  \n",
       "3       0       0             1  \n",
       "4       0       0             0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "file_name = \"../data/train_preprocessed2.csv\"\n",
    "train_df = pd.read_csv(file_name, low_memory = False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data : Divide Test and Train set\n",
    "\n",
    "array = train_df.values\n",
    "\n",
    "data = array[:, 0:70]\n",
    "target = array[:, 70]\n",
    "\n",
    "data, target\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size = test_size, random_state = seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 84.78% (2.85%)\n"
     ]
    }
   ],
   "source": [
    "# XGB Training default Result (kfold cross validation)\n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric = 'auc')\n",
    "\n",
    "# make predictions with kfold cross validation score\n",
    "kfold = KFold(n_splits = 5, random_state = 7)\n",
    "results = cross_val_score(model, data, target, cv = kfold)\n",
    "accuracy = results.mean()*100\n",
    "print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a XGB Train Model Function\n",
    "\n",
    "def XGB_Train_Model_using_KFold(eta, min_child_weight, max_depth, gamma, subsample,  colsample_bytree) : \n",
    "    xgb_params = {\n",
    "        'n_trees' : 250,\n",
    "        'eta' : max(eta, 0),\n",
    "        'max_depth' : int(max_depth),\n",
    "        'subsample' : max(min(subsample, 1), 0),\n",
    "        'objective' : 'reg:linear', \n",
    "        'base_score' : np.mean(target),\n",
    "        'eval_metric' : 'auc',\n",
    "        'silent' : 1,\n",
    "        'min_child_weight' : int(min_child_weight),\n",
    "        'gamma' : max(gamma, 0), \n",
    "        'colsample_bytree' : max(min(colsample_bytree, 1), 0)\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    #n_splits = int(max(n_splits_param, 2))\n",
    "    kfold = KFold(n_splits = 5, random_state = 7)\n",
    "    results = cross_val_score(model, data, target, cv = kfold)\n",
    "    accuracy = results.mean()*100\n",
    "    print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \n",
    "    '''\n",
    "    model.fit(data_train, target_train)\n",
    "    target_pred = model.predict(data_test)\n",
    "    predictions = [round(value) for value in target_pred]\n",
    "    accuracy = accuracy_score(target_test, predictions)\n",
    "    \n",
    "    '''\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Accuracy : 82.94% (5.93%)\n",
      "    1 | 00m06s | \u001b[35m  82.93637\u001b[0m | \u001b[32m            0.9360\u001b[0m | \u001b[32m   0.1114\u001b[0m | \u001b[32m   5.4282\u001b[0m | \u001b[32m     6.0369\u001b[0m | \u001b[32m            4.0633\u001b[0m | \u001b[32m     0.9237\u001b[0m | \n",
      "Accuracy : 82.04% (5.67%)\n",
      "    2 | 00m07s |   82.04070 |             0.7221 |    0.1352 |    8.7700 |      7.6457 |            15.6985 |      0.7057 | \n",
      "Accuracy : 82.17% (5.82%)\n",
      "    3 | 00m03s |   82.16702 |             0.7483 |    0.0968 |    6.8766 |      4.8334 |             9.9810 |      0.9797 | \n",
      "Accuracy : 85.15% (3.47%)\n",
      "    4 | 00m08s | \u001b[35m  85.15239\u001b[0m | \u001b[32m            0.7184\u001b[0m | \u001b[32m   0.0988\u001b[0m | \u001b[32m   3.0976\u001b[0m | \u001b[32m     8.0649\u001b[0m | \u001b[32m           17.7317\u001b[0m | \u001b[32m     0.8037\u001b[0m | \n",
      "Accuracy : 82.41% (5.78%)\n",
      "    5 | 00m05s |   82.40812 |             0.5455 |    0.0103 |    9.5263 |      7.9926 |            12.6939 |      0.9251 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Accuracy : 84.11% (3.56%)\n",
      "    6 | 00m12s |   84.10731 |             0.6234 |    0.0100 |    0.0000 |     10.0000 |            11.0668 |      0.8680 | \n",
      "Accuracy : 84.64% (3.62%)\n",
      "    7 | 00m16s |   84.63567 |             0.9567 |    0.0100 |    3.9930 |     10.0000 |            13.4675 |      0.9573 | \n",
      "Accuracy : 84.29% (2.31%)\n",
      "    8 | 00m08s |   84.29083 |             0.1000 |    0.0100 |    1.2809 |      8.4969 |            16.8407 |      0.5000 | \n",
      "Accuracy : 84.81% (3.17%)\n",
      "    9 | 00m15s |   84.80778 |             1.0000 |    0.2000 |    3.5169 |      8.7290 |             8.1453 |      1.0000 | \n",
      "Accuracy : 83.96% (4.44%)\n",
      "   10 | 00m15s |   83.95825 |             1.0000 |    0.0100 |    2.9885 |      7.8330 |            16.2632 |      1.0000 | \n",
      "Accuracy : 83.00% (3.13%)\n",
      "   11 | 00m07s |   83.00490 |             0.1000 |    0.2000 |    3.8630 |      9.9712 |            19.2019 |      0.5000 | \n",
      "Accuracy : 82.68% (3.71%)\n",
      "   12 | 00m07s |   82.68347 |             0.1000 |    0.2000 |    4.5315 |      9.0977 |            10.4099 |      0.5000 | \n",
      "Accuracy : 83.04% (6.06%)\n",
      "   13 | 00m18s |   83.03986 |             0.8855 |    0.2000 |    2.9909 |      9.1606 |            17.4266 |      0.5000 | \n",
      "Accuracy : 83.70% (1.09%)\n",
      "   14 | 00m06s |   83.70473 |             0.1000 |    0.0100 |    3.7175 |      7.3715 |            18.6522 |      1.0000 | \n",
      "Accuracy : 82.74% (5.83%)\n",
      "   15 | 00m11s |   82.74117 |             1.0000 |    0.0100 |    4.8022 |      6.5252 |             6.9552 |      1.0000 | \n",
      "Accuracy : 84.13% (2.77%)\n",
      "   16 | 00m16s |   84.13013 |             0.9710 |    0.0100 |    1.9931 |      9.3320 |            10.8082 |      1.0000 | \n",
      "Accuracy : 83.75% (4.75%)\n",
      "   17 | 00m09s |   83.75161 |             0.2832 |    0.0100 |    6.3891 |      8.4135 |            14.1099 |      1.0000 | \n",
      "Accuracy : 83.65% (1.11%)\n",
      "   18 | 00m08s |   83.64737 |             0.1000 |    0.0100 |    2.5837 |      8.2662 |            17.8113 |      1.0000 | \n",
      "Accuracy : 82.73% (5.84%)\n",
      "   19 | 00m18s |   82.72970 |             1.0000 |    0.2000 |    3.5232 |      7.5276 |            18.1912 |      0.5000 | \n",
      "Accuracy : 84.24% (2.87%)\n",
      "   20 | 00m07s |   84.24493 |             0.1283 |    0.0100 |    5.1426 |      8.6924 |            18.0768 |      1.0000 | \n",
      "Accuracy : 84.77% (2.39%)\n",
      "   21 | 00m13s |   84.77305 |             0.4587 |    0.0100 |    0.8850 |      9.3618 |            13.7155 |      0.5000 | \n",
      "Accuracy : 82.30% (5.74%)\n",
      "   22 | 00m14s |   82.30472 |             1.0000 |    0.0916 |    7.4625 |      7.1027 |            11.6569 |      1.0000 | \n",
      "Accuracy : 84.85% (2.50%)\n",
      "   23 | 00m11s |   84.85346 |             0.4136 |    0.0100 |    3.8020 |      8.1559 |            17.8085 |      0.9692 | \n",
      "Accuracy : 83.79% (5.23%)\n",
      "   24 | 00m17s |   83.78596 |             0.7578 |    0.0100 |    1.2181 |      8.2220 |            16.0977 |      0.5000 | \n",
      "Accuracy : 84.52% (3.36%)\n",
      "   25 | 00m11s |   84.52065 |             0.2242 |    0.1560 |    1.4639 |     10.0000 |            12.2976 |      0.6211 | \n",
      "Accuracy : 85.23% (3.32%)\n",
      "   26 | 00m13s | \u001b[35m  85.23275\u001b[0m | \u001b[32m            0.6141\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   2.9807\u001b[0m | \u001b[32m     7.9729\u001b[0m | \u001b[32m           17.3922\u001b[0m | \u001b[32m     0.7228\u001b[0m | \n",
      "Accuracy : 85.09% (3.36%)\n",
      "   27 | 00m13s |   85.09487 |             0.6972 |    0.0100 |    3.0416 |      7.9787 |            17.4848 |      0.8665 | \n",
      "Accuracy : 85.05% (3.15%)\n",
      "   28 | 00m17s |   85.04895 |             0.6089 |    0.2000 |    3.2460 |      9.2520 |            13.5244 |      0.6572 | \n",
      "Accuracy : 85.21% (3.53%)\n",
      "   29 | 00m15s |   85.20969 |             0.4587 |    0.2000 |    2.9049 |      7.9905 |            17.2522 |      0.5570 | \n",
      "Accuracy : 83.54% (2.30%)\n",
      "   30 | 00m11s |   83.54447 |             0.1000 |    0.0159 |    4.1319 |      8.6001 |            18.9124 |      0.6723 | \n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \n",
    "    #Learning Rate \n",
    "    'eta' : (0.01, 0.2),\n",
    "    \n",
    "    #Minimum sum of weights : to control overfitting\n",
    "    'min_child_weight' : (1, 20), \n",
    "    \n",
    "    #Maximum depth of a tree : to control overfitting\n",
    "    'max_depth' : (2, 10),\n",
    "    \n",
    "    #minimum loss reduction required to make a split : makes algorithm conservative\n",
    "    'gamma' : (0, 10), \n",
    "    \n",
    "    #max_delta_step is not needed since data is not imbalanced\n",
    "    #'max_delta_step' : (0, 10),\n",
    "    \n",
    "    #Fraction of observations to be randomly samples for each tree\n",
    "    #Lower: prevent overfitting\n",
    "    'subsample' : (0.5, 1),\n",
    "    \n",
    "    #Fraction of columns to be randomly samples for each tree\n",
    "    'colsample_bytree' : (0.1, 1),\n",
    "    \n",
    "    #colsamble_bylevel is not needed since subsample and colsample_bytree will do the job\n",
    "    #'colsample_bylevel' = (0.1, 1),\n",
    "    \n",
    "    #L2 regularization term on weights\n",
    "    #'lambda' = (?, ?)\n",
    "    \n",
    "    #L1 regularization term on weight\n",
    "    #'alpha' = (?, ?)\n",
    "    \n",
    "    #scale_pos_weight is not needed since data is not imbalanced\n",
    "    #'scale_pos_weight' = (0, 10)\n",
    "    #'n_splits_param' : (5, 10)\n",
    "}\n",
    "\n",
    "\n",
    "xgb_bayesOPT = BayesianOptimization(XGB_Train_Model_using_KFold, xgb_params)\n",
    "xgb_bayesOPT.maximize(init_points = 5, n_iter = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's l2: 0.0937773 + 0.00539591\tcv_agg's auc: 0.94954 + 0.0060144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9495402224421168"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lightGBM default result\n",
    "\n",
    "lgb_train = lgb.Dataset(data_train, target_train)\n",
    "lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "cv_results = lgb.cv(lgb_params, lgb_train, num_boost_round=20, nfold=5, \n",
    "                verbose_eval=20, early_stopping_rounds=5)\n",
    "cv_results['auc-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightGBM\n",
    "\n",
    "def LGB_Train_Model(learning_rate, max_depth, min_child_weight, colsample_bytree, subsample ) :\n",
    "    lgb_train = lgb.Dataset(data_train, target_train)\n",
    "    lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "    \n",
    "    # specify your configurations as a dict\n",
    "    lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "        \n",
    "        \n",
    "    \n",
    "    'learning_rate': max(learning_rate, 0),\n",
    "    'max_depth': int(max_depth),\n",
    "    'min_child_weight' : int(min_child_weight),\n",
    "    'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "    'subsample' : max(min(subsample, 1), 0)\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    '''\n",
    "    gbm = lgb.train(lgb_params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds = 5,\n",
    "                    verbose_eval=False)\n",
    "    y_pred_lgb = gbm.predict(data_test, num_iteration=gbm.best_iteration)\n",
    "    # eval\n",
    "    lgb_auc=roc_auc_score(target_test,y_pred_lgb)\n",
    "    #print('lightGBM auc : %.5f' % lgb_auc)\n",
    "    return lgb_auc\n",
    "\n",
    "    '''\n",
    "    cv_results = lgb.cv(lgb_params, lgb_train, num_boost_round=20, nfold=5, \n",
    "                    verbose_eval=20, early_stopping_rounds=5)\n",
    "\n",
    "    return cv_results['auc-mean'][-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m00s | \u001b[35m   0.94673\u001b[0m | \u001b[32m            6.3537\u001b[0m | \u001b[32m         0.7169\u001b[0m | \u001b[32m     6.7204\u001b[0m | \u001b[32m            1.1867\u001b[0m | \u001b[32m     0.7949\u001b[0m | \n",
      "    2 | 00m00s |    0.91605 |             8.7095 |          1.3835 |      6.9387 |             7.5584 |      0.5763 | \n",
      "    3 | 00m00s |    0.94121 |             0.9283 |          0.8129 |      5.3449 |             3.8678 |      0.5609 | \n",
      "    4 | 00m00s |    0.93694 |             4.4692 |          0.8433 |      8.2046 |             4.2076 |      0.6203 | \n",
      "[20]\tcv_agg's l2: 0.0862046 + 0.00444534\tcv_agg's auc: 0.953721 + 0.00482988\n",
      "    5 | 00m00s | \u001b[35m   0.95372\u001b[0m | \u001b[32m            9.1434\u001b[0m | \u001b[32m         0.2678\u001b[0m | \u001b[32m     6.4696\u001b[0m | \u001b[32m            5.1790\u001b[0m | \u001b[32m     0.6774\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 00m09s |    0.88400 |             0.1000 |          0.0100 |      2.0000 |            10.0000 |      1.0000 | \n",
      "    7 | 00m09s |    0.94126 |             0.1000 |          0.0100 |     10.0000 |             1.0000 |      0.5000 | \n",
      "    8 | 00m09s |    0.88400 |            10.0000 |          0.0100 |      2.0000 |             1.0000 |      0.5000 | \n",
      "    9 | 00m09s |    0.94126 |            10.0000 |          0.0100 |     10.0000 |             1.0000 |      0.5000 | \n",
      "   10 | 00m08s |    0.88400 |             0.1000 |          0.0100 |      2.0000 |             1.0000 |      1.0000 | \n",
      "   11 | 00m11s |    0.88400 |            10.0000 |          0.0100 |      2.0000 |            10.0000 |      0.5000 | \n",
      "   12 | 00m11s |    0.94112 |             0.1000 |          0.0100 |      9.7589 |            10.0000 |      1.0000 | \n",
      "   13 | 00m11s |    0.94126 |            10.0000 |          0.0100 |     10.0000 |            10.0000 |      1.0000 | \n",
      "   14 | 00m10s |    0.92216 |             0.1000 |          2.0000 |      8.4953 |             2.2962 |      1.0000 | \n",
      "   15 | 00m09s |    0.94200 |             0.1000 |          0.0100 |      7.6830 |             5.2900 |      1.0000 | \n",
      "   16 | 00m08s |    0.94200 |             5.1976 |          0.0100 |      7.1923 |            10.0000 |      0.5000 | \n",
      "   17 | 00m07s |    0.94250 |             2.5435 |          0.0251 |      7.4118 |             1.0268 |      0.5288 | \n",
      "   18 | 00m07s |    0.92922 |             6.2406 |          0.0145 |      4.6192 |             4.3964 |      0.9734 | \n",
      "   19 | 00m07s |    0.94262 |             9.0277 |          0.0358 |      6.8572 |             2.4668 |      0.5040 | \n",
      "   20 | 00m07s |    0.92348 |             9.9379 |          1.8752 |      6.6279 |             1.1085 |      0.8647 | \n",
      "   21 | 00m07s |    0.94205 |             9.0179 |          0.0274 |      9.9100 |             5.8454 |      0.5422 | \n",
      "   22 | 00m07s |    0.94227 |             4.9354 |          0.0444 |      9.9873 |             1.0062 |      0.9198 | \n",
      "   23 | 00m08s |    0.94200 |            10.0000 |          0.0100 |      7.5457 |             7.5240 |      1.0000 | \n",
      "   24 | 00m08s |    0.87507 |             4.7954 |          1.9963 |      3.2568 |             1.2798 |      0.5209 | \n",
      "   25 | 00m07s |    0.92264 |             6.4804 |          1.8644 |     10.0000 |             1.0000 |      0.5000 | \n",
      "   26 | 00m08s |    0.92169 |             0.2082 |          1.9465 |      7.3786 |             9.9531 |      0.6179 | \n",
      "[20]\tcv_agg's l2: 0.0992245 + 0.00505748\tcv_agg's auc: 0.9469 + 0.00674343\n",
      "   27 | 00m08s |    0.94690 |             0.1096 |          0.0860 |      6.5565 |             8.8331 |      0.5119 | \n",
      "   28 | 00m09s |    0.94231 |             3.2159 |          0.0403 |      9.9399 |             9.9489 |      0.6304 | \n",
      "   29 | 00m09s |    0.94221 |             0.1000 |          0.0100 |      6.4795 |             1.0000 |      0.5000 | \n",
      "[20]\tcv_agg's l2: 0.0902651 + 0.00514388\tcv_agg's auc: 0.951286 + 0.00560707\n",
      "   30 | 00m10s |    0.95129 |             9.8664 |          0.1209 |      9.2621 |             3.3629 |      0.9957 | \n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'learning_rate' : (0.01, 2), \n",
    "    'max_depth' : (2, 10), \n",
    "    'min_child_weight' : (1, 10), \n",
    "    'colsample_bytree' : (0.1, 10), \n",
    "    'subsample' : (0.5, 1)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "lgb_bayesOPT = BayesianOptimization(LGB_Train_Model, lgb_params)\n",
    "lgb_bayesOPT.maximize(init_points = 5, n_iter = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
