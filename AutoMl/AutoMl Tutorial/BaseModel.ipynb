{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A..papers</th>\n",
       "      <th>A.papers</th>\n",
       "      <th>B.papers</th>\n",
       "      <th>C.papers</th>\n",
       "      <th>Dif.countries</th>\n",
       "      <th>Perc_non_australian</th>\n",
       "      <th>Number.people</th>\n",
       "      <th>PHD</th>\n",
       "      <th>Max.years.univ</th>\n",
       "      <th>Grants.succ</th>\n",
       "      <th>...</th>\n",
       "      <th>SEO.11</th>\n",
       "      <th>SEO.12</th>\n",
       "      <th>SEO.13</th>\n",
       "      <th>SEO.14</th>\n",
       "      <th>SEO.15</th>\n",
       "      <th>SEO.16</th>\n",
       "      <th>SEO.17</th>\n",
       "      <th>SEO.18</th>\n",
       "      <th>SEO.19</th>\n",
       "      <th>Grant.Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A..papers  A.papers  B.papers  C.papers  Dif.countries  \\\n",
       "0        4.0       2.0       0.0       0.0              1   \n",
       "1        6.0      12.0       2.0       2.0              1   \n",
       "2        7.0      20.0      20.0       7.0              2   \n",
       "3        0.0       3.0      13.0       3.0              1   \n",
       "4        3.0       0.0       1.0       0.0              1   \n",
       "\n",
       "   Perc_non_australian  Number.people  PHD  Max.years.univ  Grants.succ  \\\n",
       "0                 0.00              1  0.0             0.0          0.0   \n",
       "1                 1.00              1  1.0            20.0          0.0   \n",
       "2                 0.75              4  2.0            50.0          0.0   \n",
       "3                 1.00              2  2.0            15.0          0.0   \n",
       "4                 0.00              1  1.0            10.0          0.0   \n",
       "\n",
       "       ...       SEO.11  SEO.12  SEO.13  SEO.14  SEO.15  SEO.16  SEO.17  \\\n",
       "0      ...            0       0       0       0       0       0       0   \n",
       "1      ...            0       0       0       0       0       0       0   \n",
       "2      ...            0       0       2       0       0       0       0   \n",
       "3      ...            0       0       2       0       0       0       0   \n",
       "4      ...            0       0       0       0       0       0       1   \n",
       "\n",
       "   SEO.18  SEO.19  Grant.Status  \n",
       "0       0       0             1  \n",
       "1       0       0             1  \n",
       "2       0       0             1  \n",
       "3       0       0             1  \n",
       "4       0       0             0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "file_name = \"../data/train_preprocessed2.csv\"\n",
    "train_df = pd.read_csv(file_name, low_memory = False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data : Divide Test and Train set\n",
    "\n",
    "array = train_df.values\n",
    "\n",
    "data = array[:, 0:70]\n",
    "target = array[:, 70]\n",
    "\n",
    "data, target\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size = test_size, random_state = seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 84.78% (2.85%)\n"
     ]
    }
   ],
   "source": [
    "# XGB (parameter default) Result \n",
    "\n",
    "model = xgb.XGBClassifier(eval_metric = 'auc')\n",
    "\n",
    "# make predictions with kfold cross validation score\n",
    "kfold = KFold(n_splits = 5, random_state = 7)\n",
    "results = cross_val_score(model, data, target, cv = kfold)\n",
    "accuracy = results.mean()*100\n",
    "print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB model Function\n",
    "\n",
    "def XGB_Train_Model_using_KFold(eta, min_child_weight, max_depth, gamma, subsample,  colsample_bytree) : \n",
    "    xgb_params = {\n",
    "        'n_trees' : 250,\n",
    "        'eta' : max(eta, 0),\n",
    "        'max_depth' : int(max_depth),\n",
    "        'subsample' : max(min(subsample, 1), 0),\n",
    "        'objective' : 'reg:linear', \n",
    "        'base_score' : np.mean(target),\n",
    "        'eval_metric' : 'auc',\n",
    "        'silent' : 1,\n",
    "        'min_child_weight' : int(min_child_weight),\n",
    "        'gamma' : max(gamma, 0), \n",
    "        'colsample_bytree' : max(min(colsample_bytree, 1), 0)\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    #n_splits = int(max(n_splits_param, 2))\n",
    "    kfold = KFold(n_splits = 5, random_state = 7)\n",
    "    results = cross_val_score(model, data, target, cv = kfold)\n",
    "    accuracy = results.mean()*100\n",
    "    print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \n",
    "    '''\n",
    "    model.fit(data_train, target_train)\n",
    "    target_pred = model.predict(data_test)\n",
    "    predictions = [round(value) for value in target_pred]\n",
    "    accuracy = accuracy_score(target_test, predictions)\n",
    "    \n",
    "    '''\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Accuracy : 82.50% (5.71%)\n",
      "    1 | 00m04s | \u001b[35m  82.50010\u001b[0m | \u001b[32m            0.6818\u001b[0m | \u001b[32m   0.1838\u001b[0m | \u001b[32m   7.9422\u001b[0m | \u001b[32m     6.0980\u001b[0m | \u001b[32m           17.7053\u001b[0m | \u001b[32m     0.9851\u001b[0m | \n",
      "Accuracy : 81.83% (5.37%)\n",
      "    2 | 00m02s |   81.83384 |             0.4641 |    0.0299 |    1.9887 |      2.7288 |             1.7628 |      0.5457 | \n",
      "Accuracy : 83.50% (5.68%)\n",
      "    3 | 00m04s | \u001b[35m  83.49899\u001b[0m | \u001b[32m            0.8746\u001b[0m | \u001b[32m   0.1322\u001b[0m | \u001b[32m   2.5734\u001b[0m | \u001b[32m     4.1345\u001b[0m | \u001b[32m            6.1091\u001b[0m | \u001b[32m     0.9343\u001b[0m | \n",
      "Accuracy : 84.65% (2.53%)\n",
      "    4 | 00m04s | \u001b[35m  84.64678\u001b[0m | \u001b[32m            0.3035\u001b[0m | \u001b[32m   0.1371\u001b[0m | \u001b[32m   5.1224\u001b[0m | \u001b[32m     9.0375\u001b[0m | \u001b[32m            2.8491\u001b[0m | \u001b[32m     0.9669\u001b[0m | \n",
      "Accuracy : 85.27% (2.27%)\n",
      "    5 | 00m05s | \u001b[35m  85.26688\u001b[0m | \u001b[32m            0.3145\u001b[0m | \u001b[32m   0.1998\u001b[0m | \u001b[32m   1.2329\u001b[0m | \u001b[32m     9.3505\u001b[0m | \u001b[32m           19.2428\u001b[0m | \u001b[32m     0.7932\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "Accuracy : 81.74% (3.03%)\n",
      "    6 | 00m09s |   81.74157 |             0.1000 |    0.0331 |    0.0000 |     10.0000 |            10.9156 |      0.5000 | \n",
      "Accuracy : 84.90% (1.44%)\n",
      "    7 | 00m07s |   84.89918 |             0.1462 |    0.2000 |    3.3445 |      8.9421 |            17.5628 |      1.0000 | \n",
      "Accuracy : 84.41% (3.28%)\n",
      "    8 | 00m16s |   84.40586 |             1.0000 |    0.2000 |    1.5819 |      7.9725 |            20.0000 |      0.6152 | \n",
      "Accuracy : 82.83% (1.75%)\n",
      "    9 | 00m07s |   82.83211 |             0.1000 |    0.2000 |    7.1374 |      6.3711 |             4.9454 |      1.0000 | \n",
      "Accuracy : 83.42% (0.97%)\n",
      "   10 | 00m07s |   83.41771 |             0.1000 |    0.2000 |    2.1463 |     10.0000 |            19.9799 |      1.0000 | \n",
      "Accuracy : 83.18% (2.31%)\n",
      "   11 | 00m07s |   83.17690 |             0.1000 |    0.2000 |    0.4102 |      7.9940 |            17.2989 |      0.5000 | \n",
      "Accuracy : 83.09% (5.93%)\n",
      "   12 | 00m18s |   83.08554 |             1.0000 |    0.0100 |    3.3172 |      7.3548 |             4.3634 |      0.5742 | \n",
      "Accuracy : 83.05% (2.79%)\n",
      "   13 | 00m18s |   83.05031 |             1.0000 |    0.2000 |    1.3557 |      9.7494 |            17.9483 |      1.0000 | \n",
      "Accuracy : 83.85% (2.34%)\n",
      "   14 | 00m07s |   83.85446 |             0.1000 |    0.0577 |    2.1462 |      8.2576 |            19.0034 |      0.5000 | \n",
      "Accuracy : 83.03% (1.62%)\n",
      "   15 | 00m06s |   83.02723 |             0.1000 |    0.2000 |    5.1439 |      7.6745 |            12.9723 |      1.0000 | \n",
      "Accuracy : 83.11% (1.22%)\n",
      "   16 | 00m06s |   83.10752 |             0.1000 |    0.2000 |    4.2329 |      5.7249 |             3.1956 |      1.0000 | \n",
      "Accuracy : 82.61% (1.40%)\n",
      "   17 | 00m07s |   82.61370 |             0.1000 |    0.2000 |    0.0644 |      8.7707 |            19.8873 |      1.0000 | \n",
      "Accuracy : 83.98% (3.05%)\n",
      "   18 | 00m08s |   83.98102 |             0.1000 |    0.2000 |    5.4067 |      8.6238 |             5.0118 |      0.9947 | \n",
      "Accuracy : 82.79% (5.97%)\n",
      "   19 | 00m11s |   82.78721 |             0.7540 |    0.2000 |    5.4753 |      7.4655 |            16.8040 |      1.0000 | \n",
      "Accuracy : 84.14% (2.35%)\n",
      "   20 | 00m09s |   84.14160 |             0.1000 |    0.2000 |    1.9760 |      7.9188 |            11.0659 |      0.6433 | \n",
      "Accuracy : 85.00% (3.25%)\n",
      "   21 | 00m18s |   85.00296 |             0.6271 |    0.2000 |    1.5464 |      8.9655 |            19.2956 |      0.8479 | \n",
      "Accuracy : 84.29% (2.30%)\n",
      "   22 | 00m11s |   84.29079 |             0.1000 |    0.2000 |    1.4024 |      9.4748 |            18.7524 |      0.5000 | \n",
      "Accuracy : 83.58% (0.69%)\n",
      "   23 | 00m09s |   83.57834 |             0.1000 |    0.2000 |    2.1598 |      8.4532 |            14.9594 |      1.0000 | \n",
      "Accuracy : 83.83% (1.27%)\n",
      "   24 | 00m10s |   83.83111 |             0.1000 |    0.2000 |    1.1898 |      9.2595 |            19.0403 |      1.0000 | \n",
      "Accuracy : 83.80% (3.39%)\n",
      "   25 | 00m22s |   83.79710 |             1.0000 |    0.1126 |    0.7307 |      9.7204 |            20.0000 |      0.5000 | \n",
      "Accuracy : 83.13% (5.83%)\n",
      "   26 | 00m14s |   83.13162 |             0.5654 |    0.0295 |    5.5522 |      7.8063 |             3.7207 |      0.7806 | \n",
      "Accuracy : 85.21% (2.57%)\n",
      "   27 | 00m13s |   85.20945 |             0.4294 |    0.2000 |    1.2037 |      9.1183 |            19.7744 |      0.5000 | \n",
      "Accuracy : 84.00% (2.87%)\n",
      "   28 | 00m08s |   84.00395 |             0.1000 |    0.2000 |    4.5555 |      6.0962 |             6.3972 |      0.9846 | \n",
      "Accuracy : 84.38% (5.11%)\n",
      "   29 | 00m10s |   84.38313 |             0.4493 |    0.1350 |    2.4156 |      4.0692 |             3.7720 |      0.7020 | \n",
      "Accuracy : 83.75% (4.42%)\n",
      "   30 | 00m14s |   83.75142 |             0.4525 |    0.2000 |    3.7995 |      8.5489 |            17.6748 |      0.5000 | \n"
     ]
    }
   ],
   "source": [
    "#XGB (parameters tuned by Bayesian Optimization) result\n",
    "\n",
    "xgb_params = {\n",
    "    \n",
    "    #Learning Rate \n",
    "    'eta' : (0.01, 0.2),\n",
    "    \n",
    "    #Minimum sum of weights : to control overfitting\n",
    "    'min_child_weight' : (1, 20), \n",
    "    \n",
    "    #Maximum depth of a tree : to control overfitting\n",
    "    'max_depth' : (2, 10),\n",
    "    \n",
    "    #minimum loss reduction required to make a split : makes algorithm conservative\n",
    "    'gamma' : (0, 10), \n",
    "    \n",
    "    #max_delta_step is not needed since data is not imbalanced\n",
    "    #'max_delta_step' : (0, 10),\n",
    "    \n",
    "    #Fraction of observations to be randomly samples for each tree\n",
    "    #Lower: prevent overfitting\n",
    "    'subsample' : (0.5, 1),\n",
    "    \n",
    "    #Fraction of columns to be randomly samples for each tree\n",
    "    'colsample_bytree' : (0.1, 1),\n",
    "    \n",
    "    #colsamble_bylevel is not needed since subsample and colsample_bytree will do the job\n",
    "    #'colsample_bylevel' = (0.1, 1),\n",
    "    \n",
    "    #L2 regularization term on weights\n",
    "    #'lambda' = (?, ?)\n",
    "    \n",
    "    #L1 regularization term on weight\n",
    "    #'alpha' = (?, ?)\n",
    "    \n",
    "    #scale_pos_weight is not needed since data is not imbalanced\n",
    "    #'scale_pos_weight' = (0, 10)\n",
    "    #'n_splits_param' : (5, 10)\n",
    "}\n",
    "\n",
    "\n",
    "xgb_bayesOPT = BayesianOptimization(XGB_Train_Model_using_KFold, xgb_params)\n",
    "xgb_bayesOPT.maximize(init_points = 5, n_iter = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20]\tcv_agg's auc: 0.94954 + 0.0060144\tcv_agg's l2: 0.0937773 + 0.00539591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9495402224421168"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lightGBM (parameter default) result\n",
    "\n",
    "lgb_train = lgb.Dataset(data_train, target_train)\n",
    "lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "cv_results = lgb.cv(lgb_params, lgb_train, num_boost_round=20, nfold=5, \n",
    "                verbose_eval=20, early_stopping_rounds=5)\n",
    "cv_results['auc-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LGB model function (eval metric = auc, using kfold)\n",
    "\n",
    "def LGB_Train_Model(learning_rate, max_depth, min_child_weight, colsample_bytree, subsample ) :\n",
    "    lgb_train = lgb.Dataset(data_train, target_train)\n",
    "    lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "    \n",
    "    # specify your configurations as a dict\n",
    "    lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "        \n",
    "        \n",
    "    \n",
    "    'learning_rate': max(learning_rate, 0),\n",
    "    'max_depth': int(max_depth),\n",
    "    'min_child_weight' : int(min_child_weight),\n",
    "    'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "    'subsample' : max(min(subsample, 1), 0)\n",
    "    }\n",
    "\n",
    "    cv_results = lgb.cv(lgb_params, lgb_train, num_boost_round=20, nfold=5, \n",
    "                    verbose_eval=20, early_stopping_rounds=5)\n",
    "\n",
    "    return cv_results['auc-mean'][-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "[20]\tcv_agg's auc: 0.934641 + 0.00900282\tcv_agg's l2: 0.110407 + 0.00650444\n",
      "    1 | 00m00s | \u001b[35m   0.93464\u001b[0m | \u001b[32m            2.1226\u001b[0m | \u001b[32m         0.7158\u001b[0m | \u001b[32m     2.7484\u001b[0m | \u001b[32m            7.0980\u001b[0m | \u001b[32m     0.7328\u001b[0m | \n",
      "    2 | 00m00s | \u001b[35m   0.94739\u001b[0m | \u001b[32m            2.5823\u001b[0m | \u001b[32m         0.5638\u001b[0m | \u001b[32m     8.7595\u001b[0m | \u001b[32m            9.5459\u001b[0m | \u001b[32m     0.8920\u001b[0m | \n",
      "[20]\tcv_agg's auc: 0.943509 + 0.00615786\tcv_agg's l2: 0.098954 + 0.00503382\n",
      "    3 | 00m00s |    0.94351 |             8.7015 |          0.3612 |      3.6977 |             4.5547 |      0.5885 | \n",
      "    4 | 00m00s |    0.92216 |             4.9546 |          1.7841 |      8.4787 |             8.2556 |      0.8559 | \n",
      "[20]\tcv_agg's auc: 0.948378 + 0.00543927\tcv_agg's l2: 0.0933521 + 0.00434557\n",
      "    5 | 00m00s | \u001b[35m   0.94838\u001b[0m | \u001b[32m            1.9040\u001b[0m | \u001b[32m         0.2965\u001b[0m | \u001b[32m     4.4612\u001b[0m | \u001b[32m            8.8118\u001b[0m | \u001b[32m     0.8473\u001b[0m | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "[20]\tcv_agg's auc: 0.915504 + 0.00542391\tcv_agg's l2: 0.13673 + 0.00324148\n",
      "    6 | 00m07s |    0.91550 |             9.6609 |          0.0837 |      2.5233 |             9.7798 |      0.5315 | \n",
      "    7 | 00m08s |    0.94126 |             0.1000 |          0.0100 |     10.0000 |             1.0000 |      1.0000 | \n",
      "[20]\tcv_agg's auc: 0.952766 + 0.00594151\tcv_agg's l2: 0.0862288 + 0.0058573\n",
      "    8 | 00m08s | \u001b[35m   0.95277\u001b[0m | \u001b[32m           10.0000\u001b[0m | \u001b[32m         0.2382\u001b[0m | \u001b[32m    10.0000\u001b[0m | \u001b[32m            1.1592\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "[20]\tcv_agg's auc: 0.908927 + 0.00444548\tcv_agg's l2: 0.151939 + 0.00293792\n",
      "    9 | 00m09s |    0.90893 |             7.8337 |          0.0577 |      2.7372 |             1.1195 |      0.9762 | \n",
      "   10 | 00m08s |    0.94112 |             8.7065 |          0.0100 |      9.9300 |             8.1194 |      0.5000 | \n",
      "   11 | 00m08s |    0.94126 |             0.5060 |          0.0100 |     10.0000 |             5.2679 |      0.5000 | \n",
      "   12 | 00m08s |    0.94126 |             6.2883 |          0.0100 |     10.0000 |             3.0354 |      1.0000 | \n",
      "[20]\tcv_agg's auc: 0.918288 + 0.0218237\tcv_agg's l2: 0.124021 + 0.0179387\n",
      "   13 | 00m09s |    0.91829 |             0.1959 |          1.4116 |      2.0388 |             9.9868 |      0.7545 | \n",
      "   14 | 00m08s |    0.94244 |             9.9828 |          0.0285 |      7.6396 |             5.1289 |      0.9187 | \n",
      "   15 | 00m08s |    0.92904 |             0.1000 |          0.0100 |      4.5184 |             1.0000 |      0.5000 | \n",
      "   16 | 00m08s |    0.94103 |             0.2896 |          0.0150 |      9.5989 |             9.9031 |      0.5278 | \n",
      "   17 | 00m08s |    0.94200 |             5.2656 |          0.0100 |      7.1571 |             9.6858 |      0.5000 | \n",
      "   18 | 00m09s |    0.92264 |             0.1936 |          1.9966 |      9.4055 |             1.0451 |      0.9534 | \n",
      "   19 | 00m09s |    0.88962 |             9.9950 |          1.9135 |      2.6329 |             3.2912 |      0.5033 | \n",
      "[20]\tcv_agg's auc: 0.94953 + 0.00569872\tcv_agg's l2: 0.0925148 + 0.00511249\n",
      "   20 | 00m09s |    0.94953 |             0.1457 |          0.1205 |      6.3444 |             7.3481 |      0.9920 | \n",
      "   21 | 00m09s |    0.94221 |             4.4439 |          0.0100 |      6.9938 |             2.5320 |      0.5000 | \n",
      "   22 | 00m12s |    0.88400 |             5.5154 |          0.0100 |      2.0000 |             7.9275 |      1.0000 | \n",
      "   23 | 00m09s |    0.92169 |             1.0111 |          2.0000 |      7.1111 |            10.0000 |      0.5000 | \n",
      "   24 | 00m08s |    0.88548 |             0.1336 |          0.0460 |      2.6975 |             7.8224 |      0.5126 | \n",
      "   25 | 00m10s |    0.71405 |             0.1000 |          2.0000 |      2.0000 |             1.0000 |      1.0000 | \n",
      "   26 | 00m12s |    0.92264 |            10.0000 |          2.0000 |     10.0000 |            10.0000 |      1.0000 | \n",
      "   27 | 00m14s |    0.93750 |            10.0000 |          0.0100 |      5.5872 |             1.0000 |      0.5000 | \n",
      "   28 | 00m13s |    0.90542 |            10.0000 |          2.0000 |      4.4422 |            10.0000 |      1.0000 | \n",
      "   29 | 00m11s |    0.92264 |            10.0000 |          2.0000 |     10.0000 |             1.0000 |      1.0000 | \n",
      "   30 | 00m12s |    0.94126 |            10.0000 |          0.0100 |     10.0000 |            10.0000 |      1.0000 | \n"
     ]
    }
   ],
   "source": [
    "#lightGBM (parameters tuned with Bayesian Optimization) Result\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate' : (0.01, 2), \n",
    "    'max_depth' : (2, 10), \n",
    "    'min_child_weight' : (1, 10), \n",
    "    'colsample_bytree' : (0.1, 10), \n",
    "    'subsample' : (0.5, 1)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "lgb_bayesOPT = BayesianOptimization(LGB_Train_Model, lgb_params)\n",
    "lgb_bayesOPT.maximize(init_points = 5, n_iter = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12500 candidates, totalling 62500 fits\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(eval_metric = 'auc', n_trees = 250)\n",
    "\n",
    "xgb_params = {\n",
    "    'learning_rate' : np.arange(0.01, 0.20, 0.04), # 5\n",
    "    'min_child_weight' : np.arange(1, 20, 4),      # 5\n",
    "    'max_depth' : np.arange(2, 10, 2),             # 4 \n",
    "    'gamma' : np.arange(0, 10, 2),                 # 5\n",
    "    'subsample' : np.arange(0.5, 1.0, 0.1),        # 5\n",
    "    'colsample_bytree' : np.arange(0.1, 1.0, 0.2), # 5\n",
    "    'objective' : ['reg:linear'],\n",
    "    'silent' : [1],\n",
    "}\n",
    "\n",
    "GSCV = GridSearchCV(xgb_clf, xgb_params, cv = 5, scoring = 'roc_auc', n_jobs = 1, verbose = 1)\n",
    "\n",
    "start_time = time.time()\n",
    "GSCV.fit(data, target)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"%s seconds elpased.\"%elapsed_time)\n",
    "best = rs.best_estimator_\n",
    "print(best_est)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
