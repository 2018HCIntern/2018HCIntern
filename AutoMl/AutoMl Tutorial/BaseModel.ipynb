{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A..papers</th>\n",
       "      <th>A.papers</th>\n",
       "      <th>B.papers</th>\n",
       "      <th>C.papers</th>\n",
       "      <th>Dif.countries</th>\n",
       "      <th>Perc_non_australian</th>\n",
       "      <th>Number.people</th>\n",
       "      <th>PHD</th>\n",
       "      <th>Max.years.univ</th>\n",
       "      <th>Grants.succ</th>\n",
       "      <th>...</th>\n",
       "      <th>SEO.11</th>\n",
       "      <th>SEO.12</th>\n",
       "      <th>SEO.13</th>\n",
       "      <th>SEO.14</th>\n",
       "      <th>SEO.15</th>\n",
       "      <th>SEO.16</th>\n",
       "      <th>SEO.17</th>\n",
       "      <th>SEO.18</th>\n",
       "      <th>SEO.19</th>\n",
       "      <th>Grant.Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   A..papers  A.papers  B.papers  C.papers  Dif.countries  \\\n",
       "0        4.0       2.0       0.0       0.0              1   \n",
       "1        6.0      12.0       2.0       2.0              1   \n",
       "2        7.0      20.0      20.0       7.0              2   \n",
       "3        0.0       3.0      13.0       3.0              1   \n",
       "4        3.0       0.0       1.0       0.0              1   \n",
       "\n",
       "   Perc_non_australian  Number.people  PHD  Max.years.univ  Grants.succ  \\\n",
       "0                 0.00              1  0.0             0.0          0.0   \n",
       "1                 1.00              1  1.0            20.0          0.0   \n",
       "2                 0.75              4  2.0            50.0          0.0   \n",
       "3                 1.00              2  2.0            15.0          0.0   \n",
       "4                 0.00              1  1.0            10.0          0.0   \n",
       "\n",
       "       ...       SEO.11  SEO.12  SEO.13  SEO.14  SEO.15  SEO.16  SEO.17  \\\n",
       "0      ...            0       0       0       0       0       0       0   \n",
       "1      ...            0       0       0       0       0       0       0   \n",
       "2      ...            0       0       2       0       0       0       0   \n",
       "3      ...            0       0       2       0       0       0       0   \n",
       "4      ...            0       0       0       0       0       0       1   \n",
       "\n",
       "   SEO.18  SEO.19  Grant.Status  \n",
       "0       0       0             1  \n",
       "1       0       0             1  \n",
       "2       0       0             1  \n",
       "3       0       0             1  \n",
       "4       0       0             0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "\n",
    "file_name = \"../data/train_preprocessed2.csv\"\n",
    "train_df = pd.read_csv(file_name, low_memory = False)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup data : Divide Test and Train set\n",
    "\n",
    "array = train_df.values\n",
    "\n",
    "data = array[:, 0:70]\n",
    "target = array[:, 70]\n",
    "\n",
    "data, target\n",
    "\n",
    "seed = 7\n",
    "test_size = 0.2\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size = test_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 85.81% (4.06%)\n"
     ]
    }
   ],
   "source": [
    "# set XGB Model -> parameters set default\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "# make predictions with kfold cross validation score\n",
    "kfold = KFold(n_splits = 10, random_state = 7)\n",
    "results = cross_val_score(model, data, target, cv = kfold)\n",
    "accuracy = results.mean()*100\n",
    "print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a Model function for bayesian optimization\n",
    "\n",
    "def XGB_Train_Model_using_KFold(eta, min_child_weight, max_depth, gamma, subsample,  colsample_bytree, n_splits_param) : \n",
    "    xgb_params = {\n",
    "        'n_trees' : 250,\n",
    "        'eta' : max(eta, 0),\n",
    "        'max_depth' : int(max_depth),\n",
    "        'subsample' : max(min(subsample, 1), 0),\n",
    "        'objective' : 'reg:linear', \n",
    "        'base_score' : np.mean(target),\n",
    "        'silent' : 1,\n",
    "        'min_child_weight' : int(min_child_weight),\n",
    "        'gamma' : max(gamma, 0), \n",
    "        'colsample_bytree' : max(min(colsample_bytree, 1), 0)\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    n_splits = int(max(n_splits_param, 5))\n",
    "    kfold = KFold(n_splits = n_splits, random_state = 7)\n",
    "    results = cross_val_score(model, data, target, cv = kfold)\n",
    "    accuracy = results.mean()*100\n",
    "    print(\"Accuracy : %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \n",
    "    '''\n",
    "    model.fit(data_train, target_train)\n",
    "    target_pred = model.predict(data_test)\n",
    "    predictions = [round(value) for value in target_pred]\n",
    "    accuracy = accuracy_score(target_test, predictions)\n",
    "    \n",
    "    '''\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   n_splits_param |   subsample | \n",
      "Accuracy : 84.46% (2.40%)\n",
      "    1 | 00m01s | \u001b[35m  84.46316\u001b[0m | \u001b[32m            0.1276\u001b[0m | \u001b[32m   0.0978\u001b[0m | \u001b[32m   1.6216\u001b[0m | \u001b[32m     6.5199\u001b[0m | \u001b[32m           17.0277\u001b[0m | \u001b[32m          5.7346\u001b[0m | \u001b[32m     0.6046\u001b[0m | \n",
      "Accuracy : 81.09% (5.26%)\n",
      "    2 | 00m04s |   81.08705 |             0.9244 |    0.1938 |    9.2053 |      3.6389 |            16.9497 |           6.8325 |      0.8845 | \n",
      "Accuracy : 81.83% (5.34%)\n",
      "    3 | 00m01s |   81.83375 |             0.2138 |    0.1013 |    8.7100 |      2.3717 |             1.2685 |           6.9365 |      0.5920 | \n",
      "Accuracy : 83.64% (4.20%)\n",
      "    4 | 00m16s |   83.63574 |             0.6920 |    0.1515 |    9.6650 |      9.7785 |             7.8138 |           7.3949 |      0.6082 | \n",
      "Accuracy : 81.95% (5.54%)\n",
      "    5 | 00m07s |   81.94879 |             0.7003 |    0.1837 |    9.7459 |      7.1346 |             3.6810 |           5.7423 |      0.7668 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m----------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |       eta |     gamma |   max_depth |   min_child_weight |   n_splits_param |   subsample | \n",
      "Accuracy : 84.49% (6.08%)\n",
      "    6 | 00m07s | \u001b[35m  84.48602\u001b[0m | \u001b[32m            0.1000\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   1.4615\u001b[0m | \u001b[32m     6.5433\u001b[0m | \u001b[32m            9.4578\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "Accuracy : 82.92% (3.28%)\n",
      "    7 | 00m06s |   82.92415 |             0.1000 |    0.0100 |    4.5252 |      6.7933 |            11.3355 |           6.2517 |      0.5000 | \n",
      "Accuracy : 84.54% (4.67%)\n",
      "    8 | 00m28s | \u001b[35m  84.54333\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   0.2000\u001b[0m | \u001b[32m   1.7087\u001b[0m | \u001b[32m     8.1117\u001b[0m | \u001b[32m           17.6075\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     0.9714\u001b[0m | \n",
      "Accuracy : 83.74% (4.25%)\n",
      "    9 | 00m22s |   83.73968 |             0.7253 |    0.2000 |    8.6027 |      6.4694 |             6.2061 |          10.0000 |      0.5260 | \n",
      "Accuracy : 83.45% (4.33%)\n",
      "   10 | 00m12s |   83.45158 |             0.1000 |    0.2000 |    0.3901 |      6.2975 |            15.8789 |           9.0076 |      0.5859 | \n",
      "Accuracy : 84.99% (3.43%)\n",
      "   11 | 00m20s | \u001b[35m  84.99103\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   4.0920\u001b[0m | \u001b[32m     9.7372\u001b[0m | \u001b[32m           17.9536\u001b[0m | \u001b[32m          6.9263\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "Accuracy : 85.52% (4.81%)\n",
      "   12 | 00m32s | \u001b[35m  85.51952\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   4.0060\u001b[0m | \u001b[32m     9.2818\u001b[0m | \u001b[32m            8.0840\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "Accuracy : 85.13% (3.96%)\n",
      "   13 | 00m22s |   85.12862 |             1.0000 |    0.2000 |    3.3503 |      7.6031 |            17.9064 |           7.2840 |      1.0000 | \n",
      "Accuracy : 85.40% (4.79%)\n",
      "   14 | 00m42s |   85.40456 |             1.0000 |    0.0100 |    3.5764 |     10.0000 |             9.7836 |          10.0000 |      1.0000 | \n",
      "Accuracy : 85.62% (4.82%)\n",
      "   15 | 00m49s | \u001b[35m  85.62285\u001b[0m | \u001b[32m            1.0000\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   3.4916\u001b[0m | \u001b[32m     9.0644\u001b[0m | \u001b[32m            7.0118\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "Accuracy : 85.83% (4.95%)\n",
      "   16 | 00m38s | \u001b[35m  85.82938\u001b[0m | \u001b[32m            0.5732\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   3.5683\u001b[0m | \u001b[32m     9.1913\u001b[0m | \u001b[32m            6.6311\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "Accuracy : 84.68% (6.27%)\n",
      "   17 | 00m19s |   84.68143 |             0.1000 |    0.0100 |    3.7502 |      9.3291 |             5.6477 |          10.0000 |      0.8273 | \n",
      "Accuracy : 83.30% (7.00%)\n",
      "   18 | 00m15s |   83.30347 |             0.1000 |    0.0100 |    4.7535 |      9.2182 |             8.8924 |          10.0000 |      0.5000 | \n",
      "Accuracy : 85.52% (4.70%)\n",
      "   19 | 00m18s |   85.51906 |             0.6636 |    0.0100 |    1.1959 |      9.7426 |            14.4708 |           7.9898 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([0.00591389]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 3, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 83.67% (3.61%)\n",
      "   20 | 00m12s |   83.66932 |             0.1000 |    0.1192 |    1.9424 |      9.6183 |             8.2421 |           9.0787 |      1.0000 | \n",
      "Accuracy : 85.24% (4.27%)\n",
      "   21 | 00m24s |   85.24398 |             1.0000 |    0.0100 |    3.0837 |      8.7486 |            15.3883 |           8.4770 |      1.0000 | \n",
      "Accuracy : 83.89% (4.40%)\n",
      "   22 | 00m15s |   83.88838 |             0.3934 |    0.0100 |    7.6518 |      4.6760 |             5.2616 |           7.3869 |      0.5000 | \n",
      "Accuracy : 85.25% (4.43%)\n",
      "   23 | 00m23s |   85.25494 |             0.8045 |    0.0100 |    1.6985 |      9.0445 |            16.7597 |           7.7789 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-0.00450099]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 48, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 85.50% (4.48%)\n",
      "   24 | 00m31s |   85.49627 |             1.0000 |    0.0100 |    1.3573 |      9.2668 |            12.5456 |          10.0000 |      1.0000 | \n",
      "Accuracy : 83.79% (4.96%)\n",
      "   25 | 00m13s |   83.78611 |             0.6099 |    0.1224 |    5.2340 |      7.0468 |            16.2569 |           5.7088 |      1.0000 | \n",
      "Accuracy : 84.77% (4.40%)\n",
      "   26 | 00m39s |   84.77373 |             0.7462 |    0.0100 |    4.4719 |      9.5183 |             6.6811 |           9.7206 |      0.5000 | \n",
      "Accuracy : 84.91% (6.54%)\n",
      "   27 | 00m18s |   84.91104 |             0.1436 |    0.0100 |    3.2550 |      8.2441 |             7.0053 |          10.0000 |      0.8234 | \n",
      "Accuracy : 84.29% (3.59%)\n",
      "   28 | 00m20s |   84.29031 |             1.0000 |    0.2000 |   10.0000 |      6.5502 |             7.2513 |           7.4149 |      1.0000 | \n",
      "Accuracy : 86.40% (4.49%)\n",
      "   29 | 00m32s | \u001b[35m  86.40367\u001b[0m | \u001b[32m            0.6076\u001b[0m | \u001b[32m   0.0100\u001b[0m | \u001b[32m   3.0492\u001b[0m | \u001b[32m     9.9569\u001b[0m | \u001b[32m            7.4453\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     0.6994\u001b[0m | \n",
      "Accuracy : 86.47% (4.33%)\n",
      "   30 | 00m33s | \u001b[35m  86.47252\u001b[0m | \u001b[32m            0.6168\u001b[0m | \u001b[32m   0.1596\u001b[0m | \u001b[32m   3.0567\u001b[0m | \u001b[32m     9.9986\u001b[0m | \u001b[32m            7.4507\u001b[0m | \u001b[32m         10.0000\u001b[0m | \u001b[32m     0.7066\u001b[0m | \n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    \n",
    "    #Learning Rate \n",
    "    'eta' : (0.01, 0.2),\n",
    "    \n",
    "    #Minimum sum of weights : to control overfitting\n",
    "    'min_child_weight' : (1, 20), \n",
    "    \n",
    "    #Maximum depth of a tree : to control overfitting\n",
    "    'max_depth' : (2, 10),\n",
    "    \n",
    "    #minimum loss reduction required to make a split : makes algorithm conservative\n",
    "    'gamma' : (0, 10), \n",
    "    \n",
    "    #max_delta_step is not needed since data is not imbalanced\n",
    "    #'max_delta_step' : (0, 10),\n",
    "    \n",
    "    #Fraction of observations to be randomly samples for each tree\n",
    "    #Lower: prevent overfitting\n",
    "    'subsample' : (0.5, 1),\n",
    "    \n",
    "    #Fraction of columns to be randomly samples for each tree\n",
    "    'colsample_bytree' : (0.1, 1),\n",
    "    \n",
    "    #colsamble_bylevel is not needed since subsample and colsample_bytree will do the job\n",
    "    #'colsample_bylevel' = (0.1, 1),\n",
    "    \n",
    "    #L2 regularization term on weights\n",
    "    #'lambda' = (?, ?)\n",
    "    \n",
    "    #L1 regularization term on weight\n",
    "    #'alpha' = (?, ?)\n",
    "    \n",
    "    #scale_pos_weight is not needed since data is not imbalanced\n",
    "    #'scale_pos_weight' = (0, 10)\n",
    "    'n_splits_param' : (5, 10)\n",
    "}\n",
    "\n",
    "\n",
    "xgb_bayesOPT = BayesianOptimization(XGB_Train_Model_using_KFold, xgb_params)\n",
    "xgb_bayesOPT.maximize(init_points = 5, n_iter = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightGBM\n",
    "\n",
    "def LGB_Train_Model(learning_rate, max_depth, min_child_weight, colsample_bytree, subsample ) :\n",
    "    lgb_train = lgb.Dataset(data_train, target_train)\n",
    "    lgb_eval = lgb.Dataset(data_test, target_test, reference=lgb_train)\n",
    "    \n",
    "    # specify your configurations as a dict\n",
    "    lgb_params = {\n",
    "        \n",
    "    #static parameters\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 1,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "        \n",
    "        \n",
    "    \n",
    "    'learning_rate': max(learning_rate, 0),\n",
    "    'max_depth': int(max_depth),\n",
    "    'min_child_weight' : int(min_child_weight),\n",
    "    'colsample_bytree' : max(min(colsample_bytree, 1), 0),\n",
    "    'subsample' : max(min(subsample, 1), 0)\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm = lgb.train(lgb_params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round = 20,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds = 5,\n",
    "                    verbose_eval=False)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred_lgb = gbm.predict(data_test, num_iteration=gbm.best_iteration)\n",
    "    # eval\n",
    "    lgb_auc=roc_auc_score(target_test,y_pred_lgb)\n",
    "    #print('lightGBM auc : %.5f' % lgb_auc)\n",
    "    return lgb_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m00s | \u001b[35m   0.94892\u001b[0m | \u001b[32m            7.1496\u001b[0m | \u001b[32m         0.9163\u001b[0m | \u001b[32m     6.9190\u001b[0m | \u001b[32m            1.0144\u001b[0m | \u001b[32m     0.5825\u001b[0m | \n",
      "    2 | 00m00s |    0.94178 |             5.5496 |          1.2430 |      6.9724 |             9.6937 |      0.9394 | \n",
      "    3 | 00m00s | \u001b[35m   0.96102\u001b[0m | \u001b[32m            5.5036\u001b[0m | \u001b[32m         0.1237\u001b[0m | \u001b[32m     7.6376\u001b[0m | \u001b[32m            8.7081\u001b[0m | \u001b[32m     0.6177\u001b[0m | \n",
      "    4 | 00m00s |    0.94265 |             0.3256 |          1.4206 |      2.6984 |             1.4903 |      0.5406 | \n",
      "    5 | 00m00s |    0.94412 |             9.7985 |          0.3609 |      2.0446 |             1.8776 |      0.7085 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   colsample_bytree |   learning_rate |   max_depth |   min_child_weight |   subsample | \n",
      "    6 | 00m06s |    0.94865 |             0.1000 |          0.0100 |      9.8905 |             1.0000 |      1.0000 | \n",
      "    7 | 00m06s |    0.89843 |             0.1000 |          0.0100 |      2.2204 |             8.6091 |      0.5000 | \n",
      "    8 | 00m09s |    0.94865 |            10.0000 |          0.0100 |     10.0000 |            10.0000 |      0.5000 | \n",
      "    9 | 00m09s |    0.93081 |             0.1000 |          2.0000 |     10.0000 |            10.0000 |      0.5000 | \n",
      "   10 | 00m08s |    0.94865 |             5.0165 |          0.0100 |      9.9527 |             6.7859 |      1.0000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.21037512e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 57, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   11 | 00m07s |    0.89843 |            10.0000 |          0.0100 |      2.0960 |             9.5775 |      0.5000 | \n",
      "   12 | 00m07s |    0.89843 |             4.9837 |          0.0100 |      2.5299 |             1.0080 |      0.9483 | \n",
      "   13 | 00m11s |    0.93069 |            10.0000 |          2.0000 |      6.8500 |             5.6449 |      0.5000 | \n",
      "   14 | 00m09s |    0.94865 |            10.0000 |          0.0100 |     10.0000 |             1.0000 |      0.5000 | \n",
      "   15 | 00m09s |    0.93081 |             0.1000 |          2.0000 |     10.0000 |             1.0000 |      0.5000 | \n",
      "   16 | 00m08s |    0.83801 |            10.0000 |          2.0000 |      2.0000 |             1.0000 |      0.5000 | \n",
      "   17 | 00m13s |    0.93069 |             0.1000 |          2.0000 |      6.3209 |             5.0912 |      1.0000 | \n",
      "   18 | 00m14s |    0.94944 |            10.0000 |          0.0100 |      6.1124 |             3.9197 |      1.0000 | \n",
      "   19 | 00m14s |    0.94681 |             0.1000 |          0.0100 |      5.7009 |             1.0000 |      0.5000 | \n",
      "   20 | 00m13s |    0.94865 |             4.6385 |          0.0100 |     10.0000 |             1.0000 |      0.5000 | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/gaussian_process/gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([1.46340048e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21 | 00m13s |    0.93081 |             6.4136 |          2.0000 |     10.0000 |            10.0000 |      0.5000 | \n",
      "   22 | 00m11s |    0.89843 |             7.1253 |          0.0100 |      2.0000 |             5.3529 |      0.5000 | \n",
      "   23 | 00m12s |    0.94865 |             0.1000 |          0.0100 |     10.0000 |             5.8810 |      0.5000 | \n",
      "   24 | 00m10s |    0.94765 |             0.1000 |          0.0100 |      7.7256 |            10.0000 |      1.0000 | \n",
      "   25 | 00m10s |    0.89843 |             0.1000 |          0.0100 |      2.0000 |             1.0000 |      1.0000 | \n",
      "   26 | 00m12s |    0.91887 |             0.1000 |          2.0000 |      4.6441 |            10.0000 |      0.5000 | \n",
      "   27 | 00m10s |    0.93792 |            10.0000 |          0.0100 |      4.8637 |             1.0000 |      0.5000 | \n",
      "   28 | 00m10s |    0.94865 |             8.5471 |          0.0100 |     10.0000 |             4.7186 |      0.5000 | \n",
      "   29 | 00m10s |    0.94865 |             2.3472 |          0.0100 |     10.0000 |             9.6377 |      0.5000 | \n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'learning_rate' : (0.01, 2), \n",
    "    'max_depth' : (2, 10), \n",
    "    'min_child_weight' : (1, 10), \n",
    "    'colsample_bytree' : (0.1, 10), \n",
    "    'subsample' : (0.5, 1)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "lgb_bayesOPT = BayesianOptimization(LGB_Train_Model, lgb_params)\n",
    "lgb_bayesOPT.maximize(init_points = 5, n_iter = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
