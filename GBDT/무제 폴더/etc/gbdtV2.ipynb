{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garb47/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/garb47/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "import time, os, random, sys\n",
    "import math\n",
    "import hyperopt.tpe\n",
    "import hpsklearn.components\n",
    "import hpsklearn.demo_support\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_lr_train_test(libsvmFileName):\n",
    "    #GBDT\n",
    "    start = time.clock()\n",
    "    train_df, test_df = train_test_split(example, train_size = 0.8,random_state=42)\n",
    "    X_train = train_df.drop(['Unnamed: 0', 'Grant.Status'], axis=1)\n",
    "    y_train = train_df['Grant.Status']\n",
    "    X_test = test_df.drop(['Unnamed: 0', 'Grant.Status'], axis=1)\n",
    "    y_test = test_df['Grant.Status']\n",
    "    param_test1 = {'n_estimators':range(20,81,10)}\n",
    "    gbclf = GradientBoostingClassifier(n_estimators=30, max_depth=4, verbose=0, random_state=10)\n",
    "    \n",
    "    \n",
    "    \n",
    "    tuned_parameter = [{'n_estimators':[100], 'max_depth':[ 6, 7], 'max_features':[0.5]}]\n",
    "    gs_clf = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10)\n",
    "    gs_clf.fit(X_train, y_train)\n",
    "    print('best parameters set found: ')\n",
    "    print(gs_clf.best_params_)\n",
    "    y_pred_gbdt = gs_clf.predict_proba(X_test)[:, 1]\n",
    "    gbdt_auc = roc_auc_score(y_test, y_pred_gbdt)\n",
    "    print('gbdt auc: %.5f' % gbdt_auc)\n",
    "    gbclf=GradientBoostingClassifier(**gs_clf.best_params_, random_state=10)\n",
    "    gbclf.fit(X_train,y_train)\n",
    "    X_train_leaves = gbclf.apply(X_train)[:,:,0]\n",
    "    (train_rows, cols) = X_train_leaves.shape\n",
    "    gbclf.fit(X_test,y_test)\n",
    "    X_test_leaves = gbclf.apply(X_test)[:,:,0]\n",
    "    gbdtenc = OneHotEncoder()\n",
    "    X_trans = gbdtenc.fit_transform(np.concatenate((X_train_leaves, X_test_leaves), axis=0))\n",
    "    #GBDT+LR\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_trans[:train_rows, :], y_train)\n",
    "    y_pred_gbdtlr1 = lr.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    gbdtlr_auc1 = roc_auc_score(y_test, y_pred_gbdtlr1)\n",
    "    print('gbdt+lr auc 1: %.5f' % gbdtlr_auc1)\n",
    "    lr = LogisticRegression(n_jobs=-1)\n",
    "    X_train_ext = hstack([X_trans[:train_rows, :], X_train])\n",
    "    lr.fit(X_train_ext, y_train)\n",
    "    X_test_ext = hstack([X_trans[train_rows:, :], X_test])\n",
    "    y_pred_gbdtlr2 = lr.predict_proba(X_test_ext)[:, 1]\n",
    "    gbdtlr_auc2 = roc_auc_score(y_test, y_pred_gbdtlr2)\n",
    "    print('gbdt+lr auc 2: %.5f' % gbdtlr_auc2)\n",
    "    f_time =time.clock()-start\n",
    "    print('GBDT time taken: %.2f'% f_time)\n",
    "    '''#+NB\n",
    "    gnb= GaussianNB()\n",
    "    gnb.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_nb=gbn.predict(X_trans[train_rows:, :])[:, 1]\n",
    "    gnb_auc = roc_auc_score(y_test,Y_pred_nb)\n",
    "    print('NB auc: ', gnb_auc)'''\n",
    "    start = time.clock()\n",
    "    #svc\n",
    "    svc=SVC(probability=True)\n",
    "\n",
    "    svc.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_svc=svc.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    svc_auc=roc_auc_score(y_test,Y_pred_svc)\n",
    "    print('SVC auc: %.5f' % svc_auc)\n",
    "    svc.fit(X_train_ext, y_train)\n",
    "    y_pred_svc2=svc.predict_proba(X_test_ext)[:, 1]\n",
    "    svc_auc2=roc_auc_score(y_test,y_pred_svc2)\n",
    "    print('SVC auc2: %.5f' % svc_auc2)\n",
    "    #KNN\n",
    "    knn=KNeighborsClassifier(n_neighbors = 3)\n",
    "    knn.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_knn=knn.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    knn_auc=roc_auc_score(y_test,Y_pred_knn)\n",
    "    print('KNN auc : %.5f' % knn_auc)\n",
    "    knn.fit(X_train_ext, y_train)\n",
    "    y_pred_knn2=knn.predict_proba(X_test_ext)[:, 1]\n",
    "    knn_auc2=roc_auc_score(y_test,y_pred_knn2)\n",
    "    print('KNN auc2: %.5f' % knn_auc2)\n",
    "    '''#perceptron\n",
    "    perceptron = Perceptron()\n",
    "    perceptron.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_prec=perceptron.predict(X_trans[train_rows:, :])[:, 1]\n",
    "    perc_auc=roc_auc_score(y_test,Y_pred_prec)\n",
    "    print('Perceptron auc : ', perc_auc)'''\n",
    "    '''#linear svc\n",
    "    lin = LinearSVC()\n",
    "    lin.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_lin=lin.predict(X_trans[train_rows:, :])[:, 1]\n",
    "    lin_auc=roc_auc_score(y_test,Y_pred_lin)\n",
    "    print('Linear SVC auc : ', lin_auc)'''\n",
    "    #SGD\n",
    "    sgd = SGDClassifier(loss='log')\n",
    "    sgd.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_sgd=sgd.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    sgd_auc=roc_auc_score(y_test,Y_pred_sgd)\n",
    "    print('SGD auc : %.5f' % sgd_auc)\n",
    "    sgd.fit(X_trans[:train_rows, :], y_train)\n",
    "    Y_pred_sgd2=sgd.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    sgd_auc2=roc_auc_score(y_test,Y_pred_sgd2)\n",
    "    print('SGD auc2 : %.5f' % sgd_auc2)\n",
    "    f_time =time.clock()-start\n",
    "    print('other classfier time taken: %.2f'% f_time)    \n",
    "    \n",
    "    #XGB\n",
    "    start = time.clock()\n",
    "    xgb=XGBClassifier()\n",
    "    xgb.fit(X_train,y_train)\n",
    "    Y_pred_xgb=xgb.predict(X_test)\n",
    "    xgb_auc= roc_auc_score(y_test,Y_pred_xgb)\n",
    "    \n",
    "    print('XGB auc : %.5f' % xgb_auc)\n",
    "    f_time =time.clock()-start\n",
    "    print('XGB time taken: %.2f'% f_time)\n",
    "    #lightGBM\n",
    "    '''start = time.clock()\n",
    "    \n",
    "    print('lightGBM time taken: ', time.clock()-start)'''\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_test1(file):\n",
    "    param_test1 = {'n_estimators':range(20,81,10)}\n",
    "    gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=500,min_samples_leaf=50,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "    param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch1.fit(train[predictors],train[target])\n",
    "    gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_test2(file):\n",
    "    param_test2 = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "    gsearch2 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60, max_features='sqrt', subsample=0.8, random_state=10), \n",
    "    param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch2.fit(train[predictors],train[target])\n",
    "    gsearch2.grid_scores_, gsearch2.best_params_, gsearch2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_test3(file):\n",
    "    param_test3 = {'min_samples_split':range(1000,2100,200), 'min_samples_leaf':range(30,71,10)}\n",
    "    gsearch3 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9,max_features='sqrt', subsample=0.8, random_state=10), \n",
    "    param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch3.fit(train[predictors],train[target])\n",
    "    gsearch3.grid_scores_, gsearch3.best_params_, gsearch3.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_test4(file):\n",
    "    param_test4 = {'max_features':range(7,20,2)}\n",
    "    gsearch4 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, n_estimators=60,max_depth=9, min_samples_split=1200, min_samples_leaf=60, subsample=0.8, random_state=10),\n",
    "    param_grid = param_test4, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "    gsearch4.fit(train[predictors],train[target])\n",
    "    gsearch4.grid_scores_, gsearch4.best_params_, gsearch4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
