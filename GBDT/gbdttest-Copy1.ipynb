{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "'''\n",
    "author:zhiqiangxu\n",
    "date:2016/8/7\n",
    "'''\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "import time, os, random, sys\n",
    "import math\n",
    "import hyperopt.tpe\n",
    "import hpsklearn.components\n",
    "import hpsklearn.demo_support\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetSplit(libSvmFile, trainFileName, testFileName, testSetRatio, lines):\n",
    "    dataFile = open(libSvmFile, 'r')\n",
    "    dataList = dataFile.readlines()\n",
    "    totalLines = len(dataList)\n",
    "    testFileLength = int(testSetRatio*lines)\n",
    "    trainFileLength = lines - testFileLength\n",
    "    List = range(totalLines)\n",
    "    random.shuffle(List)\n",
    "    trainFile = open(trainFileName, 'w')\n",
    "    testFile = open(testFileName, 'w')\n",
    "    posSampleCnt = 0\n",
    "    for i in range(lines):\n",
    "        if float(dataList[List[i]].split(' ')[0]) > 0.0:\n",
    "            posSampleCnt = posSampleCnt + 1\n",
    "        if i < trainFileLength:\n",
    "            trainFile.write(dataList[List[i]])\n",
    "        else:\n",
    "            testFile.write(dataList[List[i]])\n",
    "    dataFile.close()\n",
    "    trainFile.close()\n",
    "    testFile.close()\n",
    "    print('Positive Sample Count: %d' % posSampleCnt)\n",
    "    return posSampleCnt\n",
    "\n",
    "#calculate the positive and negative samples counts\n",
    "def calcPosNegCnt(libSvmFile):\n",
    "    dataFile = open(libSvmFile, 'r')\n",
    "    dataList = dataFile.readlines()\n",
    "    posSampleCnt = 0\n",
    "    negSampleCnt = 0\n",
    "    for i in range(len(dataList)):\n",
    "        if float(dataList[i].split(' ')[0]) > 0.0:\n",
    "            posSampleCnt = posSampleCnt + 1\n",
    "        else:\n",
    "            negSampleCnt = negSampleCnt + 1\n",
    "    print ('Positive Sample: %d' % posSampleCnt)\n",
    "    print ('Negative Sample: %d' % negSampleCnt)\n",
    "\n",
    "#training xgboost and using xgboost to encode test set features\n",
    "def xgboost_lr_train_test(libsvmFileNameInitial):\n",
    "    posSampleCnt = datasetSplit(libsvmFileNameInitial, 'data_train_th100', 'data_test_th100', 0.2, 1100000)\n",
    "    X_train, y_train = load_svmlight_file('data_train_th100')\n",
    "    print(X_train.shape)\n",
    "    X_test, y_test = load_svmlight_file('data_test_th100')\n",
    "    #training xgboost\n",
    "    negPosRatio = (1100000-posSampleCnt)/posSampleCnt\n",
    "    xgbclf = xgb.XGBClassifier(nthread=4, scale_pos_weight=negPosRatio, learning_rate=0.08,\n",
    "                            n_estimators=120, max_depth=5, gamma=0, subsample=0.9, colsample_bytree=0.5)\n",
    "    xgbclf.fit(X_train, y_train)\n",
    "    y_pred_train = xgbclf.predict_proba(X_train)[:, 1]\n",
    "    xgb_train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "    print('xgboost train auc: %.5f' % xgb_train_auc)\n",
    "    y_pred_test = xgbclf.predict_proba(X_test)[:, 1]\n",
    "    xgb_test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "    print('xgboost test auc: %.5f' % xgb_test_auc)\n",
    "    #using xgboost to encode train set and test set features\n",
    "    X_train_leaves = xgbclf.apply(X_train)\n",
    "    train_rows = X_train_leaves.shape[0]\n",
    "    X_test_leaves = xgbclf.apply(X_test)\n",
    "    X_leaves = np.concatenate((X_train_leaves, X_test_leaves), axis=0)\n",
    "    X_leaves = X_leaves.astype(np.int32)\n",
    "    (rows, cols) = X_leaves.shape\n",
    "    cum_count = np.zeros((1, cols), dtype=np.int32)\n",
    "    for j in range(cols):\n",
    "        if j == 0:\n",
    "            cum_count[0][j] = len(np.unique(X_leaves[:, j]))\n",
    "        else:\n",
    "            cum_count[0][j] = len(np.unique(X_leaves[:, j])) + cum_count[0][j-1]\n",
    "    print('Transform features genenrated by xgboost...')\n",
    "    for j in range(cols):\n",
    "        keyMapDict = {}\n",
    "        if j == 0:\n",
    "            initial_index = 1\n",
    "        else:\n",
    "            initial_index = cum_count[0][j-1]+1\n",
    "        for i in range(rows):\n",
    "            if keyMapDict.has_key(X_leaves[i, j]) == False:\n",
    "                keyMapDict[X_leaves[i, j]] = initial_index\n",
    "                X_leaves[i, j] = initial_index\n",
    "                initial_index = initial_index + 1\n",
    "            else:\n",
    "                X_leaves[i, j] = keyMapDict[X_leaves[i, j]]\n",
    "    #writing encoded features into file\n",
    "    print('Write xgboost learned features to file ...')\n",
    "    xgbFeatureLibsvm = open('xgb_feature_libsvm', 'w')\n",
    "    for i in range(rows):\n",
    "        if i < train_rows:\n",
    "            xgbFeatureLibsvm.write(str(y_train[i]))\n",
    "        else:\n",
    "            xgbFeatureLibsvm.write(str(y_test[i-train_rows]))\n",
    "        for j in range(cols):\n",
    "            xgbFeatureLibsvm.write(' '+str(X_leaves[i, j])+':1.0')\n",
    "        xgbFeatureLibsvm.write('\\n')\n",
    "    xgbFeatureLibsvm.close()\n",
    "\n",
    "#using xgboost encoded feature in lr to calculate auc\n",
    "def xgb_feature_lr_train_test(xgbfeaturefile, origin_libsvm_file):\n",
    "    datasetSplit(origin_libsvm_file, 'data_train_th100', 'data_test_th100', 0.2, 1100000)\n",
    "    datasetSplit(xgbfeaturefile, 'xgb_feature_train_libsvm','xgb_feature_test_libsvm', 0.2, 1100000)\n",
    "    X_train_origin, y_train_origin = load_svmlight_file('data_train_th100')\n",
    "    X_test_origin, y_test_origin = load_svmlight_file('data_test_th100')\n",
    "    X_train, y_train = load_svmlight_file('xgb_feature_train_libsvm')\n",
    "    print(X_train.shape)\n",
    "    X_test, y_test = load_svmlight_file('xgb_feature_test_libsvm')\n",
    "    print(X_test.shape)\n",
    "\n",
    "    #fittting lr using just xgboost encoded feature\n",
    "    lr = LogisticRegression(n_jobs=-1, C=0.1, penalty='l1')\n",
    "    lr.fit(X_train, y_train)\n",
    "    joblib.dump(lr, 'lr.m')\n",
    "    y_pred_train = lr.predict_proba(X_train)[:, 1]\n",
    "    lr_train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "    print('LR Train AUC: %.5f' % lr_train_auc)\n",
    "    y_pred_test = lr.predict_proba(X_test)[:, 1]\n",
    "    lr_test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "    print('LR Test AUC: %.5f' % lr_test_auc)\n",
    "\n",
    "    # fitting lr using xgboost encoded feature and original feature\n",
    "    X_train_ext = hstack([X_train_origin, X_train])\n",
    "    print(X_train_ext.shape)\n",
    "    del(X_train)\n",
    "    del(X_train_origin)\n",
    "    X_test_ext = hstack([X_test_origin, X_test])\n",
    "    print(X_test_ext.shape)\n",
    "    del(X_test)\n",
    "    del(X_test_origin)\n",
    "    lr = LogisticRegression(n_jobs=-1, C=0.1, penalty='l1')\n",
    "    lr.fit(X_train_ext, y_train)\n",
    "    joblib.dump(lr, 'lr_ext.m')\n",
    "    y_pred_train = lr.predict_proba(X_train_ext)[:, 1]\n",
    "    lr_train_auc = roc_auc_score(y_train, y_pred_train)\n",
    "    print('LR Ext Train AUC: %.5f' % lr_train_auc)\n",
    "    y_pred_test = lr.predict_proba(X_test_ext)[:, 1]\n",
    "    lr_test_auc = roc_auc_score(y_test, y_pred_test)\n",
    "    print('LR Ext Test AUC: %.5f' % lr_test_auc)\n",
    "\n",
    "#using gbdt, gbdt+lr to calculate auc\n",
    "def gbdt_lr_train_test(libsvmFileName):\n",
    "    datasetSplit(libsvmFileName, 0.2, 'label_feature_data_train', 'label_feature_data_test', 600000)\n",
    "    X_train, y_train = load_svmlight_file('label_feature_data_train')\n",
    "    X_test, y_test = load_svmlight_file('label_feature_data_test')\n",
    "    gbclf = GradientBoostingClassifier(n_estimators=30, max_depth=4, verbose=0)\n",
    "    tuned_parameter = [{'n_estimators':[30, 40, 50, 60], 'max_depth':[3, 4, 5, 6], 'max_features':[0.5,0.7,0.9]}]\n",
    "    gs_clf = GridSearchCV(gbclf, tuned_parameter, cv=5, scoring='roc_auc')\n",
    "    gs_clf.fit(X_train.toarray(), y_train)\n",
    "    print('best parameters set found: ')\n",
    "    print(gs_clf.best_params_)\n",
    "    y_pred_gbdt = gs_clf.predict_proba(X_test.toarray())[:, 1]\n",
    "    gbdt_auc = roc_auc_score(y_test, y_pred_gbdt)\n",
    "    print('gbdt auc: %.5f' % gbdt_auc)\n",
    "    X_train_leaves = gbclf.apply(X_train)[:,:,0]\n",
    "    (train_rows, cols) = X_train_leaves.shape\n",
    "    X_test_leaves = gbclf.apply(X_test)[:,:,0]\n",
    "    gbdtenc = OneHotEncoder()\n",
    "    X_trans = gbdtenc.fit_transform(np.concatenate((X_train_leaves, X_test_leaves), axis=0))\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_trans[:train_rows, :], y_train)\n",
    "    y_pred_gbdtlr1 = lr.predict_proba(X_trans[train_rows:, :])[:, 1]\n",
    "    gbdtlr_auc1 = roc_auc_score(y_test, y_pred_gbdtlr1)\n",
    "    print('gbdt+lr auc 1: %.5f' % gbdtlr_auc1)\n",
    "    lr = LogisticRegression(n_jobs=-1)\n",
    "    X_train_ext = hstack([X_trans[:train_rows, :], X_train])\n",
    "    lr.fit(X_train_ext, y_train)\n",
    "    X_test_ext = hstack([X_trans[train_rows:, :], X_test])\n",
    "    y_pred_gbdtlr2 = lr.predict_proba(X_test_ext)[:, 1]\n",
    "    gbdtlr_auc2 = roc_auc_score(y_test, y_pred_gbdtlr2)\n",
    "    print('gbdt+lr auc 2: %.5f' % gbdtlr_auc2)\n",
    "\n",
    "#using lr to calculate auc on original data and cross featured data\n",
    "def lr_train_test(libsvmFileInitial, libsvmFileCross):\n",
    "    datasetSplit(libsvmFileInitial, 'data_train_th500', 'data_test_th500', 0.2, 1100000)\n",
    "    datasetSplit(libsvmFileCross, 'data_cross_train_th500', 'data_cross_test_th500', 0.2, 1100000)\n",
    "    X_train_origin, y_train_origin = load_svmlight_file('data_train_th500')\n",
    "    print(X_train_origin.shape)\n",
    "    X_test_origin, y_test_origin = load_svmlight_file('data_test_th500')\n",
    "    print(X_test_origin.shape)\n",
    "    lr = LogisticRegression(C=0.1, penalty='l2')\n",
    "    lr.fit(X_train_origin, y_train_origin)\n",
    "    y_pred_train = lr.predict_proba(X_train_origin)[:, 1]\n",
    "    lr_train_auc = roc_auc_score(y_train_origin, y_pred_train)\n",
    "    print('lr train auc origin: %.5f' % lr_train_auc)\n",
    "    y_pred_test = lr.predict_proba(X_test_origin)[:, 1]\n",
    "    lr_test_auc = roc_auc_score(y_test_origin, y_pred_test)\n",
    "    print('lr test auc origin: %.5f' % lr_test_auc)\n",
    "    X_train_cross, y_train_cross = load_svmlight_file('data_cross_train_th500')\n",
    "    print(X_train_cross.shape)\n",
    "    X_test_cross, y_test_cross = load_svmlight_file('data_cross_test_th500')\n",
    "    print(X_test_cross.shape)\n",
    "    lr = LogisticRegression(C=0.1, penalty='l2')\n",
    "    lr.fit(X_train_cross, y_train_cross)\n",
    "    y_pred_train = lr.predict_proba(X_train_cross)[:, 1]\n",
    "    lr_train_auc = roc_auc_score(y_train_cross, y_pred_train)\n",
    "    print('lr train auc cross: %.5f' % lr_train_auc)\n",
    "    y_pred_test = lr.predict_proba(X_test_cross)[:, 1]\n",
    "    lr_test_auc = roc_auc_score(y_test_cross, y_pred_test)\n",
    "    print('lr test auc cross: %.5f' % lr_test_auc)\n",
    "\n",
    "#using hyperopt-sklearn to automatically tune the parameters of gbdt\n",
    "def hyper_opt(libsvmFile):\n",
    "    datasetSplit(libsvmFile, 'data_train_th100', 'data_test_th100', 0.2, 100000)\n",
    "    X_train, y_train = load_svmlight_file('data_train_th100')\n",
    "    X_train = X_train.toarray()\n",
    "    estimator = hpsklearn.HyperoptEstimator(None,\n",
    "                                            classifier=hpsklearn.components.any_classifier('clf'),\n",
    "                                            algo=hyperopt.tpe.suggest,\n",
    "                                            trial_timeout=10.0,\n",
    "                                            max_evals=10)\n",
    "    fit_iterator = estimator.fit_iter(X_train, y_train)\n",
    "    fit_iterator.next()\n",
    "    plot_helper = hpsklearn.demo_support.PlotHelper(estimator, mintodate_ylim=(0.0,0.1))\n",
    "    while len(estimator.trials.trials) < estimator.max_evals:\n",
    "        fit_iterator.send(1)\n",
    "        plot_helper.post_iter()\n",
    "    plot_helper.post_loop()\n",
    "    estimator.retrain_best_model_on_full_data(X_train, y_train)\n",
    "    print ('Best classifier: \\n', estimator.best_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('example.csv', low_memory= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Sponsor.Code</th>\n",
       "      <th>Grant.Category.Code</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept.No..1</th>\n",
       "      <th>Faculty.No..1</th>\n",
       "      <th>With.PHD.1</th>\n",
       "      <th>No..of.Years.in.Uni.at.Time.of.Grant.1</th>\n",
       "      <th>Number.of.Successful.Grant.1</th>\n",
       "      <th>Number.of.Unsuccessful.Grant.1</th>\n",
       "      <th>A..1</th>\n",
       "      <th>A.1</th>\n",
       "      <th>B.1</th>\n",
       "      <th>C.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "      <td>7243.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4418.237195</td>\n",
       "      <td>0.461273</td>\n",
       "      <td>37.035759</td>\n",
       "      <td>2.435593</td>\n",
       "      <td>1.783239</td>\n",
       "      <td>314458.012702</td>\n",
       "      <td>74.702250</td>\n",
       "      <td>161142.789314</td>\n",
       "      <td>17.858249</td>\n",
       "      <td>93703.271711</td>\n",
       "      <td>...</td>\n",
       "      <td>2447.041143</td>\n",
       "      <td>23.752865</td>\n",
       "      <td>0.653597</td>\n",
       "      <td>3.007594</td>\n",
       "      <td>1.272953</td>\n",
       "      <td>2.249344</td>\n",
       "      <td>4.137512</td>\n",
       "      <td>5.683833</td>\n",
       "      <td>4.438630</td>\n",
       "      <td>2.334944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2503.443512</td>\n",
       "      <td>0.498532</td>\n",
       "      <td>65.905933</td>\n",
       "      <td>2.246809</td>\n",
       "      <td>2.461627</td>\n",
       "      <td>51573.773907</td>\n",
       "      <td>26.805598</td>\n",
       "      <td>160451.041441</td>\n",
       "      <td>19.494936</td>\n",
       "      <td>146750.691945</td>\n",
       "      <td>...</td>\n",
       "      <td>733.626488</td>\n",
       "      <td>11.262292</td>\n",
       "      <td>0.475856</td>\n",
       "      <td>1.464322</td>\n",
       "      <td>1.569585</td>\n",
       "      <td>2.980506</td>\n",
       "      <td>7.893441</td>\n",
       "      <td>8.051083</td>\n",
       "      <td>5.991703</td>\n",
       "      <td>4.399000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210000.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2276.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>280204.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2298.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4437.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>320702.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>240202.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2628.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6608.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>321202.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>320702.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>270107.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2813.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8707.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>999999.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>440209.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>440207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4418.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Grant.Status  Sponsor.Code  Grant.Category.Code  \\\n",
       "count  7243.000000   7243.000000   7243.000000          7243.000000   \n",
       "mean   4418.237195      0.461273     37.035759             2.435593   \n",
       "std    2503.443512      0.498532     65.905933             2.246809   \n",
       "min       0.000000      0.000000      0.000000             0.000000   \n",
       "25%    2276.500000      0.000000      2.000000             1.000000   \n",
       "50%    4437.000000      0.000000      4.000000             1.000000   \n",
       "75%    6608.500000      1.000000     34.000000             3.000000   \n",
       "max    8707.000000      1.000000    437.000000            13.000000   \n",
       "\n",
       "       Contract.Value.Band...see.note.A    RFCD.Code.1  RFCD.Percentage.1  \\\n",
       "count                       7243.000000    7243.000000        7243.000000   \n",
       "mean                           1.783239  314458.012702          74.702250   \n",
       "std                            2.461627   51573.773907          26.805598   \n",
       "min                            0.000000  210000.000000           5.000000   \n",
       "25%                            0.000000  280204.000000          50.000000   \n",
       "50%                            1.000000  320702.000000          80.000000   \n",
       "75%                            2.000000  321202.000000         100.000000   \n",
       "max                           16.000000  999999.000000         100.000000   \n",
       "\n",
       "         RFCD.Code.2  RFCD.Percentage.2    RFCD.Code.3     ...       \\\n",
       "count    7243.000000        7243.000000    7243.000000     ...        \n",
       "mean   161142.789314          17.858249   93703.271711     ...        \n",
       "std    160451.041441          19.494936  146750.691945     ...        \n",
       "min         0.000000           0.000000       0.000000     ...        \n",
       "25%         0.000000           0.000000       0.000000     ...        \n",
       "50%    240202.000000          10.000000       0.000000     ...        \n",
       "75%    320702.000000          30.000000  270107.000000     ...        \n",
       "max    440209.000000          90.000000  440207.000000     ...        \n",
       "\n",
       "        Dept.No..1  Faculty.No..1   With.PHD.1  \\\n",
       "count  7243.000000    7243.000000  7243.000000   \n",
       "mean   2447.041143      23.752865     0.653597   \n",
       "std     733.626488      11.262292     0.475856   \n",
       "min      28.000000       1.000000     0.000000   \n",
       "25%    2298.000000      25.000000     0.000000   \n",
       "50%    2628.000000      25.000000     1.000000   \n",
       "75%    2813.000000      25.000000     1.000000   \n",
       "max    4418.000000     187.000000     1.000000   \n",
       "\n",
       "       No..of.Years.in.Uni.at.Time.of.Grant.1  Number.of.Successful.Grant.1  \\\n",
       "count                             7243.000000                   7243.000000   \n",
       "mean                                 3.007594                      1.272953   \n",
       "std                                  1.464322                      1.569585   \n",
       "min                                  0.000000                      0.000000   \n",
       "25%                                  2.000000                      0.000000   \n",
       "50%                                  3.000000                      1.000000   \n",
       "75%                                  4.000000                      2.000000   \n",
       "max                                  5.000000                     13.000000   \n",
       "\n",
       "       Number.of.Unsuccessful.Grant.1         A..1          A.1          B.1  \\\n",
       "count                     7243.000000  7243.000000  7243.000000  7243.000000   \n",
       "mean                         2.249344     4.137512     5.683833     4.438630   \n",
       "std                          2.980506     7.893441     8.051083     5.991703   \n",
       "min                          0.000000     0.000000     0.000000     0.000000   \n",
       "25%                          0.000000     0.000000     1.000000     0.000000   \n",
       "50%                          1.000000     1.000000     3.000000     2.000000   \n",
       "75%                          3.000000     5.000000     7.000000     6.000000   \n",
       "max                         26.000000   123.000000    95.000000    69.000000   \n",
       "\n",
       "               C.1  \n",
       "count  7243.000000  \n",
       "mean      2.334944  \n",
       "std       4.399000  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       3.000000  \n",
       "max      61.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe() '''label_feature_data_libsvm'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Grant.Status</th>\n",
       "      <th>Sponsor.Code</th>\n",
       "      <th>Grant.Category.Code</th>\n",
       "      <th>Contract.Value.Band...see.note.A</th>\n",
       "      <th>RFCD.Code.1</th>\n",
       "      <th>RFCD.Percentage.1</th>\n",
       "      <th>RFCD.Code.2</th>\n",
       "      <th>RFCD.Percentage.2</th>\n",
       "      <th>RFCD.Code.3</th>\n",
       "      <th>RFCD.Percentage.3</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept.No..1</th>\n",
       "      <th>Faculty.No..1</th>\n",
       "      <th>With.PHD.1</th>\n",
       "      <th>No..of.Years.in.Uni.at.Time.of.Grant.1</th>\n",
       "      <th>Number.of.Successful.Grant.1</th>\n",
       "      <th>Number.of.Unsuccessful.Grant.1</th>\n",
       "      <th>A..1</th>\n",
       "      <th>A.1</th>\n",
       "      <th>B.1</th>\n",
       "      <th>C.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>280199.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3073.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>280103.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280106.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>280203.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2538.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>321004.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>321216.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2923.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>270602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>320602.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2678.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260500.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>280000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>290000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2153.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Grant.Status  Sponsor.Code  Grant.Category.Code  \\\n",
       "0             1           0.0                  0.0   \n",
       "1             1           2.0                  1.0   \n",
       "2             1          29.0                  2.0   \n",
       "3             1          40.0                  2.0   \n",
       "4             0          59.0                  1.0   \n",
       "\n",
       "   Contract.Value.Band...see.note.A  RFCD.Code.1  RFCD.Percentage.1  \\\n",
       "0                               1.0     280199.0              100.0   \n",
       "1                               2.0     280103.0               30.0   \n",
       "2                               1.0     321004.0               60.0   \n",
       "3                               3.0     270602.0               50.0   \n",
       "4                               1.0     260500.0               34.0   \n",
       "\n",
       "   RFCD.Code.2  RFCD.Percentage.2  RFCD.Code.3  RFCD.Percentage.3 ...   \\\n",
       "0          0.0                0.0          0.0                0.0 ...    \n",
       "1     280106.0               30.0     280203.0               40.0 ...    \n",
       "2     321216.0               40.0          0.0                0.0 ...    \n",
       "3     320602.0               50.0          0.0                0.0 ...    \n",
       "4     280000.0               33.0     290000.0               33.0 ...    \n",
       "\n",
       "   Dept.No..1  Faculty.No..1  With.PHD.1  \\\n",
       "0      3073.0           31.0         0.0   \n",
       "1      2538.0           25.0         1.0   \n",
       "2      2923.0           25.0         1.0   \n",
       "3      2678.0           25.0         1.0   \n",
       "4      2153.0           19.0         1.0   \n",
       "\n",
       "   No..of.Years.in.Uni.at.Time.of.Grant.1  Number.of.Successful.Grant.1  \\\n",
       "0                                     1.0                           0.0   \n",
       "1                                     2.0                           0.0   \n",
       "2                                     3.0                           0.0   \n",
       "3                                     3.0                           0.0   \n",
       "4                                     3.0                           0.0   \n",
       "\n",
       "   Number.of.Unsuccessful.Grant.1  A..1   A.1   B.1  C.1  \n",
       "0                             0.0   4.0   2.0   0.0  0.0  \n",
       "1                             0.0   6.0  12.0   2.0  2.0  \n",
       "2                             0.0   0.0   3.0   5.0  2.0  \n",
       "3                             0.0   0.0   3.0  13.0  3.0  \n",
       "4                             0.0   3.0   0.0   1.0  0.0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,1.000000000000000000e+00,2.801990000000000000e+05,1.000000000000000000e+02,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,7.002990000000000000e+05,1.000000000000000000e+02,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,4.057200000000000000e+04,1.000000000000000000e+00,1.965000000000000000e+03,9.000000000000000000e+00,3.073000000000000000e+03,3.100000000000000000e+01,0.000000000000000000e+00,1.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,4.000000000000000000e+00,2.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-198019149fae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcalcPosNegCnt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'label_feature_data_libsvm.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdatasetSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'50018_20160625_cross_sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr_data_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr_data_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mxgboost_lr_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_libsvm_th100'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-e36d5b61680e>\u001b[0m in \u001b[0;36mcalcPosNegCnt\u001b[0;34m(libSvmFile)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mnegSampleCnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mposSampleCnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposSampleCnt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,1.000000000000000000e+00,2.801990000000000000e+05,1.000000000000000000e+02,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,7.002990000000000000e+05,1.000000000000000000e+02,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,4.057200000000000000e+04,1.000000000000000000e+00,1.965000000000000000e+03,9.000000000000000000e+00,3.073000000000000000e+03,3.100000000000000000e+01,0.000000000000000000e+00,1.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00,4.000000000000000000e+00,2.000000000000000000e+00,0.000000000000000000e+00,0.000000000000000000e+00\\n'"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    calcPosNegCnt('label_feature_data_libsvm.csv')\n",
    "    datasetSplit('50018_20160625_cross_sample', 0.2, 'lr_data_train', 'lr_data_test', 600000)\n",
    "    xgboost_lr_train_test('data_libsvm_th100')\n",
    "    lr_train_test('data_libsvm_th500', 'data_cross_libsvm_th500')\n",
    "    xgb_feature_lr_train_test('xgb_feature_libsvm', 'data_cross_libsvm_th100')\n",
    "    hyper_opt('data_libsvm_th100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_feature_data_libsvm=train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"label_feature_data_libsvm.csv\", label_feature_data_libsvm, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
