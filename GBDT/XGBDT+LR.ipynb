{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "import time, os, random, sys\n",
    "import math\n",
    "import hyperopt.tpe\n",
    "import hpsklearn.components\n",
    "import hpsklearn.demo_support\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_lr(File):\n",
    "    \n",
    "    start = time.clock()\n",
    "    train_df, test_df = train_test_split(File, train_size = 0.8)\n",
    "    X_train = train_df.drop(train_df.columns[0], axis=1)\n",
    "    y_train = train_df[train_df.columns[0]]\n",
    "    X_test = test_df.drop(test_df.columns[0], axis=1)\n",
    "    y_test = test_df[test_df.columns[0]]\n",
    "    \n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train.values,y_train.values)\n",
    "    dtest = xgb.DMatrix(X_test.values, y_test.values)\n",
    "    param = {'max_depth':7, 'silent': 1, 'objective':'binary:logistic'}\n",
    "    watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "    num_round = 30\n",
    "\n",
    "    bst= xgb.train(param, dtrain, num_round)\n",
    "\n",
    "    y_pred = bst.predict(dtrain, pred_leaf=True)\n",
    "    num_leaf= 1000\n",
    "    X_train_leaves = np.zeros([len(y_pred),len(y_pred[0]) * num_leaf],dtype=np.int64)\n",
    "    for i in range(0,len(y_pred)):\n",
    "        temp = np.arange(len(y_pred[0])) * num_leaf - 1 + np.array(y_pred[i])\n",
    "        X_train_leaves[i][temp] += 1\n",
    "\n",
    "    y_pred= bst.predict(dtest, pred_leaf=True)    \n",
    "    X_test_leaves = np.zeros([len(y_pred),len(y_pred[0]) * num_leaf],dtype=np.int64)\n",
    "    for i in range(0,len(y_pred)):\n",
    "        temp = np.arange(len(y_pred[0])) * num_leaf - 1 + np.array(y_pred[i])\n",
    "        X_test_leaves[i][temp] += 1\n",
    "\n",
    "    lm = LogisticRegression(penalty='l2',C=0.1) # logestic model construction\n",
    "    lm.fit(X_train_leaves,y_train)  # fitting the data\n",
    "\n",
    "    y_pred_est = lm.predict_proba(X_test_leaves)   # Give the probabilty on each label\n",
    "\n",
    "    gbdtlr_auc1 = roc_auc_score(y_test, y_pred_est[:,1])\n",
    "    print('XGBDT+LR auc 1: %.5f' % gbdtlr_auc1)\n",
    "    \n",
    "    lr = LogisticRegression(n_jobs=-1)\n",
    "    X_train_ext = hstack([X_train_leaves, X_train])\n",
    "    lr.fit(X_train_ext, y_train)\n",
    "    X_test_ext = hstack([X_test_leaves, X_test])\n",
    "    y_pred_gbdtlr2 = lr.predict_proba(X_test_ext)[:, 1]\n",
    "    gbdtlr_auc2 = roc_auc_score(y_test, y_pred_gbdtlr2)\n",
    "    print('XGBDT+LR auc 2: %.5f' % gbdtlr_auc2)\n",
    "    f_time =time.clock()-start\n",
    "    print('XGBDT+LR time taken: %.2f'% f_time)\n",
    "    \n",
    "    #+NB\n",
    "\n",
    "    \n",
    "    start = time.clock()\n",
    "    gnb= GaussianNB()\n",
    "\n",
    "    gnb.fit(X_train_leaves, y_train)\n",
    "    Y_pred_nb=gnb.predict_proba(X_test_leaves)[:,1]\n",
    "    gnb_auc = roc_auc_score(y_test,Y_pred_nb)\n",
    "    print('GBDT + GNB auc: %.5f'% gnb_auc)    \n",
    "    '''    \n",
    "    gnb.fit(X_train_ext, y_train)\n",
    "    y_pred_gnb2=gnb.predict_proba(X_test_ext)[:,1]\n",
    "    gnb_auc2=roc_auc_score(y_test,y_pred_gnb2)\n",
    "    print('GNB auc2: %.5f' % gnb_auc2)\n",
    "    '''\n",
    "    '''#svc\n",
    "    svc=SVC(probability=True)\n",
    "    svc.fit(X_train_leaves, y_train)\n",
    "    Y_pred_svc=svc.predict_proba(X_test_leaves)[:,1]\n",
    "    svc_auc=roc_auc_score(y_test,Y_pred_svc)\n",
    "    print('GBDT + SVC auc: %.5f' % svc_auc)\n",
    "    \n",
    "    svc.fit(X_train_ext, y_train)\n",
    "    y_pred_svc2=svc.predict_proba(X_test_ext)[:, 1]\n",
    "    svc_auc2=roc_auc_score(y_test,y_pred_svc2)\n",
    "    print('GBDT + SVC auc2: %.5f' % svc_auc2)'''\n",
    "    \n",
    "    '''#KNN\n",
    "    knn=KNeighborsClassifier(n_neighbors = 3)\n",
    "    knn.fit(X_train_leaves, y_train)\n",
    "    Y_pred_knn=knn.predict_proba(X_test_leaves)[:,1]\n",
    "    knn_auc=roc_auc_score(y_test,Y_pred_knn)\n",
    "    print('GBDT + KNN auc : %.5f' % knn_auc)\n",
    "    \n",
    "    knn.fit(X_train_ext, y_train)\n",
    "    y_pred_knn2=knn.predict_proba(X_test_ext)[:, 1]\n",
    "    knn_auc2=roc_auc_score(y_test,y_pred_knn2)\n",
    "    print('GBDT + KNN auc2: %.5f' % knn_auc2)\n",
    "    '''\n",
    "    #perceptron\n",
    "\n",
    "    perceptron = Perceptron()\n",
    "    perceptron.fit(X_train_leaves, y_train)\n",
    "    y_pred_perc=perceptron.predict(X_test_leaves)\n",
    "    perc_auc=roc_auc_score(y_test,y_pred_perc)\n",
    "    print('GBDT + Perceptron auc : %.5f' % perc_auc)\n",
    "    \n",
    "    perceptron.fit(X_train_ext, y_train)\n",
    "    y_pred_perc2=perceptron.predict(X_test_ext)\n",
    "    perc_auc2=roc_auc_score(y_test,y_pred_perc2)\n",
    "    print('GBDT + Perceptron auc2 : %.5f' % perc_auc2 )\n",
    "    \n",
    "    #linear svc\n",
    "\n",
    "    lin = LinearSVC()\n",
    "    lin.fit(X_train_leaves, y_train)\n",
    "    y_pred_lin=lin.predict(X_test_leaves)\n",
    "    lin_auc=roc_auc_score(y_test,y_pred_lin)\n",
    "    print('GBDT + Linear SVC auc : %.5f' % lin_auc)\n",
    "    \n",
    "    lin.fit(X_train_ext, y_train)\n",
    "    y_pred_lin2=lin.predict(X_test_ext)\n",
    "    lin_auc2=roc_auc_score(y_test,y_pred_lin2)\n",
    "    print('GBDT + Linear SVC auc2 : %.5f' % lin_auc2)\n",
    "    \n",
    "    #SGD\n",
    "\n",
    "    sgd = SGDClassifier(loss='log')\n",
    "    sgd.fit(X_train_leaves, y_train)\n",
    "    Y_pred_sgd=sgd.predict_proba(X_test_leaves)[:, 1]\n",
    "    sgd_auc=roc_auc_score(y_test,Y_pred_sgd)\n",
    "    print('GBDT + SGD auc : %.5f' % sgd_auc)\n",
    "    \n",
    "    sgd.fit(X_train_ext, y_train)\n",
    "    Y_pred_sgd2=sgd.predict_proba(X_test_ext)[:, 1]\n",
    "    sgd_auc2=roc_auc_score(y_test,Y_pred_sgd2)\n",
    "    print('GBDT + SGD auc2 : %.5f' % sgd_auc2)\n",
    "    f_time =time.clock()-start\n",
    "    print('GBDT + other classfier time taken: %.2f'% f_time)    \n",
    "    \n",
    "    #XGB\n",
    "    start = time.clock()\n",
    "    xgbc=XGBClassifier()\n",
    "    xgbc.fit(X_train,y_train)\n",
    "    Y_pred_xgb=xgbc.predict_proba(X_test)[:,1]\n",
    "    xgb_auc= roc_auc_score(y_test,Y_pred_xgb)\n",
    "    print('XGB auc : %.5f' % xgb_auc)\n",
    "    \n",
    "    '''#XGB with leaves\n",
    "\n",
    "    xgbc.fit(X_train_leaves,y_train)\n",
    "    Y_pred_xgb=xgbc.predict(X_test_leaves)\n",
    "    xgb_auc= roc_auc_score(y_test,Y_pred_xgb)\n",
    "    print('GBDT + XGB auc: %.5f' % xgb_auc)\n",
    "    \n",
    "    #XGB with features ext\n",
    "    \n",
    "    xgbc.fit(X_train_ext, y_train)\n",
    "    y_pred_xgb2=xgbc.predict(X_test_ext)\n",
    "    xgb_auc2=roc_auc_score(y_test,y_pred_xgb2)\n",
    "    print('GBDT + XGB auc2: %.5f' %xgb_auc2)\n",
    "    \n",
    "    f_time =time.clock()-start\n",
    "    print('XGB time taken: %.2f'% f_time)'''\n",
    "    \n",
    "    #lightGBM\n",
    "    start = time.clock()\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2', 'auc'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "    \n",
    "    }\n",
    "\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=20,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=5,\n",
    "                    verbose_eval=False)\n",
    "\n",
    "\n",
    "\n",
    "    y_pred_lgb = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "    # eval\n",
    "    lgb_auc=roc_auc_score(y_test,y_pred_lgb)\n",
    "    print('lightGBM auc : %.5f' % lgb_auc)\n",
    "    \n",
    "    lgb_train=lgb.Dataset(X_train_leaves, y_train)\n",
    "    lgb_eval=lgb.Dataset(X_test_leaves, y_test, reference=lgb_train)\n",
    "    gbm = lgb.train(params,\n",
    "                  lgb_train,\n",
    "                    num_boost_round=20,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=5,\n",
    "                   verbose_eval=False)\n",
    "    y_pred_lgb2 =gbm.predict(X_test_leaves, num_iteration=gbm.best_iteration)\n",
    "    lgb_auc2=roc_auc_score(y_test, y_pred_lgb2)\n",
    "    \n",
    "    print('GBDT + lightGBM auc : %.5f' % lgb_auc2)\n",
    "    \n",
    "    lgb_train=lgb.Dataset(X_train_ext, y_train)\n",
    "    lgb_eval=lgb.Dataset(X_test_ext, y_test, reference=lgb_train)\n",
    "    gbm = lgb.train(params,\n",
    "                  lgb_train,\n",
    "                    num_boost_round=20,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=5,\n",
    "                   verbose_eval=False)\n",
    "    y_pred_lgb3 =gbm.predict(X_test_ext, num_iteration=gbm.best_iteration)\n",
    "    lgb_auc3=roc_auc_score(y_test, y_pred_lgb3)\n",
    "    \n",
    "    print('GBDT + lightGBM auc2 : %.5f' % lgb_auc3)\n",
    "    \n",
    "    \n",
    "    f_time=time.clock()-start\n",
    "    print('lightGBM time taken: %.2f'% f_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = pd.read_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBDT+LR auc 1: 0.94069\n",
      "XGBDT+LR auc 2: 0.62187\n",
      "XGBDT+LR time taken: 6.23\n",
      "GBDT + GNB auc: 0.86978\n",
      "GBDT + Perceptron auc : 0.79588\n",
      "GBDT + Perceptron auc2 : 0.48035\n",
      "GBDT + Linear SVC auc : 0.85587\n",
      "GBDT + Linear SVC auc2 : 0.46910\n",
      "GBDT + SGD auc : 0.92947\n",
      "GBDT + SGD auc2 : 0.52675\n",
      "GBDT + other classfier time taken: 14.77\n",
      "XGB auc : 0.93379\n",
      "lightGBM auc : 0.93402\n",
      "GBDT + lightGBM auc : 0.93368\n",
      "GBDT + lightGBM auc2 : 0.93126\n",
      "lightGBM time taken: 2.91\n"
     ]
    }
   ],
   "source": [
    "xgboost_lr(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBDT+LR auc 1: 0.92607\n",
      "XGBDT+LR auc 2: 0.56891\n",
      "XGBDT+LR time taken: 4.43\n",
      "GBDT + GNB auc: 0.86347\n",
      "GBDT + Perceptron auc : 0.85147\n",
      "GBDT + Perceptron auc2 : 0.50000\n",
      "GBDT + Linear SVC auc : 0.84385\n",
      "GBDT + Linear SVC auc2 : 0.50617\n",
      "GBDT + SGD auc : 0.91063\n",
      "GBDT + SGD auc2 : 0.49945\n",
      "GBDT + other classfier time taken: 13.48\n",
      "XGB auc : 0.93151\n",
      "lightGBM auc : 0.92760\n",
      "GBDT + lightGBM auc : 0.92417\n",
      "GBDT + lightGBM auc2 : 0.91973\n",
      "lightGBM time taken: 3.01\n"
     ]
    }
   ],
   "source": [
    "xgboost_lr(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBDT+LR auc 1: 0.93185\n",
      "XGBDT+LR auc 2: 0.54976\n",
      "XGBDT+LR time taken: 4.46\n",
      "GBDT + GNB auc: 0.85293\n",
      "GBDT + Perceptron auc : 0.80626\n",
      "GBDT + Perceptron auc2 : 0.51418\n",
      "GBDT + Linear SVC auc : 0.82021\n",
      "GBDT + Linear SVC auc2 : 0.50000\n",
      "GBDT + SGD auc : 0.91307\n",
      "GBDT + SGD auc2 : 0.50317\n",
      "GBDT + other classfier time taken: 13.79\n",
      "XGB auc : 0.92898\n",
      "lightGBM auc : 0.92622\n",
      "GBDT + lightGBM auc : 0.92848\n",
      "GBDT + lightGBM auc2 : 0.93084\n",
      "lightGBM time taken: 2.94\n"
     ]
    }
   ],
   "source": [
    "xgboost_lr(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
