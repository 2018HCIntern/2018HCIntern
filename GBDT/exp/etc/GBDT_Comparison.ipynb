{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/garb47/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/garb47/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "import time, os, random, sys\n",
    "import math\n",
    "import hyperopt.tpe\n",
    "import hpsklearn.components\n",
    "import hpsklearn.demo_support\n",
    "import warnings\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 1500)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbdt_lr_train_test(File):\n",
    "    #GBDT\n",
    "    start = time.clock()\n",
    "    train_df, test_df = train_test_split(File, train_size = 0.8)\n",
    "    X_train = train_df.drop(train_df.columns[0], axis=1)\n",
    "    y_train = train_df[train_df.columns[0]]\n",
    "    X_test = test_df.drop(test_df.columns[0], axis=1)\n",
    "    y_test = test_df[test_df.columns[0]]\n",
    "    \n",
    "    gbclf = GradientBoostingClassifier(random_state=42)\n",
    "    gbclf.fit(X_train,y_train)\n",
    "    X_train_leaves = gbclf.apply(X_train)[:,:,0]\n",
    "    (train_rows, cols) = X_train_leaves.shape\n",
    "    gbclf.fit(X_test,y_test)\n",
    "    X_test_leaves = gbclf.apply(X_test)[:,:,0]\n",
    "    \n",
    "    lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "    lr.fit(X_train_leaves, y_train)\n",
    "    y_pred_gbdtlr1 = lr.predict(X_test_leaves)\n",
    "    gbdtlr_auc1 = roc_auc_score(y_test, y_pred_gbdtlr1)\n",
    "    print('GBDT+LR auc  : %.5f' % gbdtlr_auc1)\n",
    "    f_time =time.clock()-start\n",
    "    print('GBDT+LR time taken: %.2f'% f_time)\n",
    "    #training xgboost\n",
    "    start = time.clock()\n",
    "    xgbclf = xgb.XGBClassifier(random_state=42)\n",
    "    xgbclf.fit(X_train, y_train)\n",
    "    \n",
    "    #using xgboost to encode train set and test set features\n",
    "    X_train_leaves = xgbclf.apply(X_train)\n",
    "    train_rows = X_train_leaves.shape[0]\n",
    "    xgbclf.fit(X_test, y_test)\n",
    "    X_test_leaves = xgbclf.apply(X_test)\n",
    "    \n",
    "    \n",
    "    #fittting lr using just xgboost encoded feature\n",
    "    lr = LogisticRegression( C=0.1, penalty='l1')\n",
    "    lr.fit(X_train_leaves,y_train)\n",
    "    \n",
    "    y_pred = lr.predict(X_test_leaves)\n",
    "    gbdtlr_auc1 = roc_auc_score(y_test, y_pred)\n",
    "    print('XGBDT+LR AUC : %.5f' % gbdtlr_auc1)\n",
    "    \n",
    "    f_time =time.clock()-start\n",
    "    print('XGBDT+LR time taken: %.2f'% f_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example=pd.read_csv('example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.56903\n",
      "GBDT+LR time taken: 11.79\n",
      "XGBDT+LR AUC : 0.46416\n",
      "XGBDT+LR time taken: 16.71\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)      # trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.56998\n",
      "GBDT+LR time taken: 12.72\n",
      "XGBDT+LR AUC : 0.47052\n",
      "XGBDT+LR time taken: 15.83\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)     # trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.61470\n",
      "GBDT+LR time taken: 13.07\n",
      "XGBDT+LR AUC : 0.66579\n",
      "XGBDT+LR time taken: 10.73\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)      # trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.71012\n",
      "GBDT+LR time taken: 11.10\n",
      "XGBDT+LR AUC : 0.52431\n",
      "XGBDT+LR time taken: 20.33\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)       # trial 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.55783\n",
      "GBDT+LR time taken: 9.89\n",
      "XGBDT+LR AUC : 0.56154\n",
      "XGBDT+LR time taken: 12.90\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)      # random_state applied for both classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.34758\n",
      "GBDT+LR time taken: 8.49\n",
      "XGBDT+LR AUC : 0.62272\n",
      "XGBDT+LR time taken: 10.22\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)      # random_state applied for both classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT+LR auc  : 0.36613\n",
      "GBDT+LR time taken: 5.47\n",
      "XGBDT+LR AUC : 0.36081\n",
      "XGBDT+LR time taken: 11.53\n"
     ]
    }
   ],
   "source": [
    "gbdt_lr_train_test(example)      # random_state applied for both classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
